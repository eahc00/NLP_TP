{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pytorch_lightning\n",
    "from nlp_datasets import get_dataloader, get_dataset\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "text_decoder_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    lagacy = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09209843d33e4860a65f6d1848a166d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True, \n",
    "    quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in base_model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[손해배상(기)]〈일제 강제동원 피해자들이 일본 기업을 상대로 불법행위로 인한 위자료 지급을 구하는 사건〉 [공2024상,204]\\n판시사항:[1] 객관적으로 채권자가 권리를 행사할 수 없는 장애사유가 있었던 경우, 채무자가 소멸시효 완성을 주장하는 것이 신의성실의 원칙에 반하는 권리남용에 해당하는지 여부(적극)\\n[2] 채권자에게 권리의 행사를 기대할 수 없는 객관적인 사실상의 장애사유가 있었으나 대법원이 채권자의 권리행사가 가능하다는 법률적 판단을 내린 경우, 그 시점 이후에는 장애사유가 해소되었다고 볼 수 있는지 여부(원칙적 적극)\\n[3] 일제강점기에 강제동원되어 기간 군수사업체인 구 미쓰비시중공업 주식회사에서 강제노동에 종사한 갑 등이 위 회사가 해산된 후 새로이 설립된 미쓰비시중공업 주식회사를 상대로 위자료 지급을 구한 사안에서, 강제동원 피해자의 일본 기업에 대한 위자료청구권은 ‘대한민국과 일본국 간의 재산 및 청구권에 관한 문제의 해결과 경제협력에 관한 협정’의 적용 대상에 포함되지 않는다는 법적 견해를 최종적으로 명확하게 밝힌 대법원 2018. 10. 30. 선고 2013다61381 전원합의체 판결이 선고될 때까지는 강제동원 피해자 또는 그 상속인들에게는 미쓰비시중공업 주식회사를 상대로 객관적으로 권리를 사실상 행사할 수 없는 장애사유가 있었다고 봄이 타당하다고 한 사례\\n\\n        assistant : \\n    ', 'label': '\\n그러므로 상고를 모두 기각하고 상고비용은 패소자가 부담하도록 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유(상고이유서 제출기간이 지난 후에 제출된 상고이유보충서의 기재는 상고이유를 보충하는 범위 내에서)를 판단한다.\\n1. 제1 상고이유에 대하여\\n원심은 판시와 같은 이유로 대한민국은 이 사건의 당사자 및 분쟁이 된 사안과 실질적 관련성이 있다고 할 것이어서 대한민국 법원이 이 사건에 대하여 국제재판관할권을 가진다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 국제재판관할에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n2. 제2 상고이유에 대하여\\n원심은 판시와 같은 이유를 들어 원고 1, 원고 2와 망 소외 1, 망 소외 2(이하 ‘원고 등’이라고 한다)를 노역에 종사하게 한 미쓰비시중공업 주식회사(이하 ‘구 미쓰비시중공업’이라고 한다)가 일본국 법률이 정한 바에 따라 해산되고 그 판시의 ‘제2회사’가 설립된 뒤 흡수합병의 과정을 거쳐 피고로 변경되는 등의 절차를 거쳤다고 하더라도, 구 미쓰비시중공업과 피고는 그 실질에 있어 동일성을 그대로 유지하고 있다고 보는 것이 타당하므로 원고 1, 원고 2, 원고 3과 망 소외 2(이하 ‘원고들’이라고 한다)는 구 미쓰비시중공업에 대한 이 사건 손해배상청구권을 피고에 대하여도 행사할 수 있다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 외국법인의 동일성 판단 기준 및 외국법 적용에 있어서의 공서양속 위반 여부에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n3. 제3 상고이유에 대하여\\n원심은, 「대한민국과 일본국 간의 재산 및 청구권에 관한 문제의 해결과 경제협력에 관한 협정」(이하 ‘청구권협정’이라고 한다)에 의하여 원고들의 피고에 대한 이 사건 손해배상청구권이 소멸하였는지에 관하여, 판시와 같은 이유를 들어, 원고들의 손해배상청구권은 일본 정부의 한반도에 대한 불법적인 식민지배 및 침략전쟁의 수행과 직결된 일본 기업의 반인도적인 불법행위를 전제로 하는 강제동원 피해자의 일본 기업에 대한 위자료청구권이라는 전제하에, 이러한 위자료청구권은 청구권협정의 적용 대상에 포함되었다고 볼 수 없다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 청구권협정의 적용 대상 및 효력에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n4. 제4 상고이유에 대하여\\n가. 채무자의 소멸시효를 이유로 한 항변권의 행사도 민법의 대원칙인 신의성실의 원칙과 권리남용금지의 원칙의 지배를 받는 것이어서 객관적으로 채권자가 권리를 행사할 수 없는 장애사유가 있었다면 채무자가 소멸시효 완성을 주장하는 것은 신의성실의 원칙에 반하는 권리남용으로서 허용될 수 없다(대법원 2011. 9. 8. 선고 2009다66969 판결 등 참조).\\n나. 원심은 피고의 소멸시효 완성 주장에 대해서 원고들이 이 사건 소를 제기한 2014. 2. 27. 무렵까지도 원고들에게는 객관적으로 손해배상청구권을 사실상 행사할 수 없는 장애사유가 있었다고 봄이 상당하다는 이유로 피고의 위 주장은 신의성실의 원칙에 반하는 권리남용으로 허용될 수 없다고 판단하였는바, 이 부분 원심판결의 이유를 위와 같은 법리와 기록에 비추어 살펴본다.\\n1) 채권자에게 권리의 행사를 기대할 수 없는 객관적인 사실상의 장애사유가 있었던 경우에도 대법원이 이에 관하여 채권자의 권리행사가 가능하다는 법률적 판단을 내렸다면 특별한 사정이 없는 한 그 시점 이후에는 그러한 장애사유가 해소되었다고 볼 수 있다.\\n2) 대법원은 2012. 5. 24. 선고한 2009다68620 판결 및 2009다22549 판결(이하 이를 합쳐 ‘2012년 판결’이라고 한다)에서 일제강점기에 강제동원된 피해자들의 일본 기업에 대한 불법행위를 이유로 한 손해배상청구권이 청구권협정의 적용 대상에 포함되지 않았다는 이유로 그 청구권이 소멸되지 않았다고 판단하였다.\\n3) 그러나 2012년 판결 선고 이후에도 청구권협정의 적용 대상에 강제동원 피해자들의 일본 기업에 대한 불법행위를 이유로 한 손해배상청구권이 포함되는지 여부 등에 관하여 여전히 국내외에서 논란이 계속되었고, 청구권협정의 당사자인 일본 정부는 청구권협정에 의하여 과거 일본 정부나 일본 기업 등이 관여한 반인도적 불법행위나 식민지배와 직결된 불법행위로 인한 손해배상청구권도 소멸되었다는 입장을 여전히 고수하였으며, 피고를 비롯한 일본 기업들도 이에 동조하면서 배상을 거부하였다. 이러한 상황에서 대한민국 정부는 남은 사법절차를 지켜보아야 한다는 것 외에 별다른 공식적인 입장표명은 하지 않았다.\\n4) 2012년 판결은 파기환송 취지의 판결로서 그로써 해당 사건 당사자들의 권리가 확정적으로 인정된 것이 아니었다. 또한 환송판결의 기속력도 환송 후 재판에서 새로 제출되는 주장과 증거에 따라 미치지 않을 수도 있었다(대법원 1988. 3. 8. 선고 87다카1396 판결 등 참조). 이러한 상황에서 원고 등과 같은 피해자들로서는 2012년 판결 선고 이후에도 개별적으로 일본 기업을 상대로 한 소송을 통해 실질적인 피해구제를 받을 수 있는지에 대하여 여전히 의구심을 가질 수 있었다.\\n5) 대법원은 2012년 판결 중 2009다68620 사건의 재상고심인 2013다61381 사건에서 2018. 10. 30. 전원합의체 판결(이하 ‘2018년 전원합의체 판결’이라고 한다)로써, 강제동원 피해자들의 일본 기업에 대한 불법행위를 이유로 한 위자료청구권이 청구권협정의 적용 대상에 포함되지 않았다고 판단한 후 같은 취지의 환송 후 원심의 판단을 유지하여 상고를 기각하였다. 이로써 대법원은 2018년 전원합의체 판결을 통해 일본 정부의 한반도에 대한 불법적인 식민지배 및 침략전쟁의 수행과 직결된 일본 기업의 반인도적인 불법행위를 전제로 하는 강제동원 피해자의 일본 기업에 대한 위자료청구권은 청구권협정의 적용 대상에 포함되지 않는다는 법적 견해를 최종적으로 명확하게 밝혔다.\\n6) 결국 2018년 전원합의체 판결 선고로 비로소 대한민국 내에서 강제동원 피해자들의 사법적 구제가능성이 확실하게 되었다고 볼 수 있다.\\n7) 이러한 사정을 고려할 때, 강제동원 피해자 또는 그 상속인인 원고들에게는 2018년 전원합의체 판결이 선고될 때까지는 피고를 상대로 객관적으로 권리를 사실상 행사할 수 없는 장애사유가 있었다고 봄이 상당하다.\\n다. 따라서 같은 취지의 원심의 위와 같은 판단에 상고이유 주장과 같이 소멸시효에 관한 법리 등을 오해하여 판결 결과에 영향을 미친 잘못이 없다.\\n5. 제5 상고이유에 대하여\\n불법행위로 입은 정신적 고통에 대한 위자료 액수에 관하여는 사실심 법원이 제반 사정을 참작하여 그 직권에 속하는 재량에 의하여 이를 확정할 수 있다(대법원 1999. 4. 23. 선고 98다41377 판결 등 참조).\\n원심은 판시와 같은 이유로 원고들에 대한 위자료 액수를 정하였다. 원심판결 이유를 기록에 비추어 살펴보면, 원심의 이 부분 판단에 상고이유 주장과 같이 위자료 산정에 관한 법리를 오해하는 등의 잘못이 없다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c267db41b34adfa43e01d6a2d1bce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[재산세부과처분취소]〈오피스텔을 주택으로 취급하여 재산세를 부과할 수 있는지 문제된 사건〉 [공2024상,64]\\n판시사항:오피스텔이 재산세 과세대상인 ‘주택’에 해당하는지 판단하는 기준\\n\\n        assistant : \\n    ', 'label': '\\n그러므로 상고를 기각하고 상고비용은 패소자가 부담하도록 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유를 판단한다.\\n1. 관련 법리\\n지방세법 제105조, 제104조 제2호, 제6조 제4호, 건축법 제2조 제1항 제2호, 제2항 및 그 위임에 따른 건축법 시행령 제3조의5 [별표 1] 제14호는 재산세 과세대상인 ‘건축물’ 중 일반업무시설의 하나로 ‘오피스텔(업무를 주로 하며, 분양하거나 임대하는 구획 중 일부 구획에서 숙식을 할 수 있도록 한 건축물로서 국토교통부장관이 고시하는 기준에 적합한 것을 말한다)’을 명시하였고, 지방세법 제105조, 제104조 제3호, 구 주택법(2021. 12. 21. 법률 제18631호로 개정되기 전의 것, 이하 같다) 제2조 제1호는 재산세 과세대상인 ‘주택’을 ‘세대의 구성원이 장기간 독립된 주거생활을 할 수 있는 구조로 된 건축물의 전부 또는 일부 및 그 부속토지’로 정하면서, 재산세 과세대상인 토지와 건축물의 범위에서 주택은 제외한다고 규정하였다.\\n구 지방세법 시행령(2021. 12. 31. 대통령령 제32293호로 개정되기 전의 것) 제119조는 ‘재산세의 과세대상 물건이 공부상 등재 현황과 사실상의 현황이 다른 경우에는 사실상 현황에 따라 재산세를 부과한다.’고 규정하였으므로, 재산세 과세대상인 ‘주택’에 해당하는지 여부는 특별한 사정이 없는 한 공부상의 용도에 관계없이 재산세 과세기준일 현재 사실상 주거용으로 사용되는지를 기준으로 판단함이 타당하다.\\n2. 판단\\n원심은, 원고가 이 사건 각 오피스텔을 「민간임대주택에 관한 특별법」에 따라 민간임대주택으로 등록한 후 주거용으로 임대한 사실 등 판시와 같은 사정을 인정한 다음, 이 사건 각 오피스텔의 공부상 등재 현황은 일반업무시설인 오피스텔이고, 구 주택법 및 그 시행령이 업무시설에 해당하는 오피스텔(업무를 주로 하며, 분양하거나 임대하는 구획 중 일부 구획에서 숙식을 할 수 있도록 한 건축물로서 국토교통부장관이 고시하는 기준에 적합한 것)을 준주택(주택 외의 건축물과 그 부속토지로서 주거시설로 이용가능한 시설 등)으로 분류하고 있더라도 사실상의 현황에 따라 주택으로 취급하여 재산세 등을 부과한 처분은 적법하다는 취지로 판단하였다.\\n원심판결 이유를 관련 규정과 법리, 기록에 비추어 살펴보면, 원심의 판단에 이 사건 각 오피스텔의 법적 성격에 관한 법리 등을 오해함으로써 판결에 영향을 미친 잘못이 없다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059720e68900424d8b0e1cac15c809c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = get_dataloader()\n",
    "valid_dataloader = get_dataloader(split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 8,172,867,584 || trainable%: 0.0577\n"
     ]
    }
   ],
   "source": [
    "## ---  LoRA --- ##\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    ")\n",
    "model = get_peft_model(base_model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "peft_model_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B_Lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "lr_scheduler = StepLR(optimizer, step_size=1, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:34<00:00,  1.58it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(16.2115, device='cuda:0') train_epoch_loss=tensor(2.7857, device='cuda:0') eval_ppl=tensor(9.4873, device='cuda:0') eval_epoch_loss=tensor(2.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 454/815 [04:47<03:48,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     18\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# lr_scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:350\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # print(batch)\n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.detach().float()\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(valid_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eahc00/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8124fd53ceef45cf84ab9222d538c9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\n",
      "        \n",
      " title:[시정명령등처분취소청구의소]〈개인정보 유출로 인한 과징금 부과처분의 취소를 구한 사건〉 [공2023하,2029]\n",
      "판시사항:[1] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항 각호에서 정한 행위에 대하여 부과하는 과징금의 성격 / 위 조항 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이득 / 위 과징금 부과를 위한 관련 매출액을 산정할 때 ‘위반행위로 인하여 직접 또는 간접적으로 영향을 받는 서비스’의 범위를 판단하는 기준\n",
      "[2] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반에 대해 부과되는 과징금의 액수를 정할 때 고려할 사항 및 과징금의 액수가 위반행위의 내용에 비해 과중하여 사회통념상 현저하게 타당성을 잃은 경우, 과징금 부과처분이 위법한지 여부(적극)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# LoRA 적용 모델 불러오기\n",
    "base_model = AutoModelForCausalLM.from_pretrained(text_decoder_id)\n",
    "load_model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decoder_id)\n",
    "\n",
    "ds = get_dataset(split=\"valid\", get_prompy_only=True)\n",
    "\n",
    "\n",
    "i = 2\n",
    "inputs = tokenizer(ds[i]['prompt'], return_tensors=\"pt\")\n",
    "print(ds[i]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:144783 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[시정명령등처분취소청구의소]〈개인정보 유출로 인한 과징금 부과처분의 취소를 구한 사건〉 [공2023하,2029]\\n판시사항:[1] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항 각호에서 정한 행위에 대하여 부과하는 과징금의 성격 / 위 조항 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이득 / 위 과징금 부과를 위한 관련 매출액을 산정할 때 ‘위반행위로 인하여 직접 또는 간접적으로 영향을 받는 서비스’의 범위를 판단하는 기준\\n[2] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반에 대해 부과되는 과징금의 액수를 정할 때 고려할 사항 및 과징금의 액수가 위반행위의 내용에 비해 과중하여 사회통념상 현저하게 타당성을 잃은 경우, 과징금 부과처분이 위법한지 여부(적극)\\n\\n    \\n원심판결 중 과징금 부과처분에 관한 부분을 파기하고 이 부분 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유를 판단한다.\\n1. 관련 법리\\n가. 구 「정보통신망 이용촉진 및 정보보호 등에 관한 법률」(2020. 5. 12. 법률 제16355호로 개정되기 전의 것, 이하 ‘2020법’이라 한다) 제64조의3 제1항은 “정보통신망 이용자가 정보통신망 사용자로부터 개인정보를 유출 또는 합승시킨다[개정 1], 개인 정보 보호를 위반하였다[개정 2]면 그 중 한 이하와 함께 과태모노폴로 벌금 500만원입니다.”로 다음과 같은 행위를 행위에 대하여 과징금을 부과하는 동시에 형사처벌이 이루어짐에 따라 그 과징금은 벌가요.(1) 2020법 제64조의3 제1항 제6호는 “자(전업·당업·대리자 등 제외)에 대하여 과징금을 부과함으로써 그 위반행위를 위반하는 이익의 범위를 과대하거나 초과함을 과대하는 행위라고 하더라도 과징금 부과를 통해 억착이나 강요와 같은 불법행위에 의한 처벌효과를 과대하는 점을 감안하지 않고 부과할 수 없다고 한 것에 반하여, 위 조항 제6호에서 지정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 이익이 인정되는 경우 그 제재효과가 미비하다고 하여 과징금이 박탈하고자 하는 이익의 가치를 고려하지 않고 부과할 수 없는 점을 추인한다고 한 규정 자체가 있었다.”라고 규정하고, 이 규정은 2020. 12. 상위법에 따라 개정된 2020법 제64조의5 제2호, 제3호가 개정되기 전의 내용에서 “자란 직접하거나 간접적으로 행위 또는 그 행위의 주체이고, 이익을 보호하거나 이행을 담당하거나 관리, 감독, 감독위원회의 직무를 하는 자연발생적 또는 법적으로 지정된 또는 지정된 개인을 말한다.”라고 규정하고, 2020법 제6호 제6호는 “자에 대하여 과징금을 부과함이 근로소비의 재연을 위한 법치에서 정당한 공익을 목적으로 하고, 근로소비의 대상이 되는 ‘서비스 이용 또는 개인 정보 유출, 개인 정보 침해 등’을 금지하는 것으로서 과징금이 자에 대하여 과징금이 부과됨으로써 근로자를 방해할 수 있는 이득이 제한되지만 여전히 방해되지 아니한 사이에 제한을 한다고 볼 수 있는 점을 의미한다.”이라고 규정하였다. 이 규정에 따라 과징금 부과처분이 형사처벌의 위조를 방지하기 위하여 허용되지 않는다[고론 1], 법규 위반 과징이 근로소비의 대상이 되는 행위에 대하여 부과함으로써 근로자의 거래를 방해하거나 방해할 우려가 있는 경우(원심판결 자료 조사로만 판결하는 것은 피고를 해치한다. 누구의 법규나 관행 등으로서도 부당한 악영향을 방지할 수 있는 과징금은 부과하되, 법규 위반에 대한 과징이 근로소비의 대상행위 또는 해당 행위에 대하여 다른 처벌 대상인 다른 처벌처분(형사처벌 또는 행정처벌)을 기대하는 것과 같이 하는 것은 허용된다.] (피고가 애초자들의 변호기로 청구한 기록에 따라 원심이 인정한 기록 있는 관점에서는 see 2008. 5. 22. 대법원 2007. 25. 대법번호 2008.3.22 전원준판 2008), 원심판결 이유를 참고한 결과, 피고의 이러한 상고이유에 대한 주장이 인정되는 부분은 위법하지만, 피고의 이러한 상고이유판단(이하 ‘이 사건 처분에 대한 상고이유판단’을 respectively calls)을 취소하고 제2, 3 상고이유 요청은 무시한 상태로 판단을 한다.\\n나. 2020법 제64조의3 제1항 제6호에서 정한 행위에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 영역을 위반하는 행위는 그 자에 대하여 과징금이 행위와 직계적으로 박탈하고자 하는 이익의 가치를 고려하여 부과하는 것과 비교하여, 과징금 부과를 통해 억착이나 강요와 같은 불법행위에 의한 처벌효과를 고려하는 것이 더 합리적이므로, 2020법 제64조의3 제1항에 따라 2020법 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의성을 못 알아보는 것은 구 「개인정보보호법」(2020. 5. 20. 법률 제13765호로 개정되기 전의 것, 이하 ‘2020개인정보보호법’) 제6호의 자에 대하여 과징이 과태료로서의 형을 부과함으로써 행위자의 이익만을 중시하는 것과 같은 위 이유로, 피로로 인한 비난, 모욕, 욕설, 모욕적 행위 등 등 다른 형태의 인권침해 피해자가 발생할 우려가 있고 그 피해자는 과징금을 부담하여 개인정보 보호의 효과를 어느 정도 보장 받을 수 있을지도 않는 채 법치발달을 위한 과징금 부과처분에 그 법적 판매행위 변별, 서비스 이용을 방해하는 효과를 낼 수 있는 하찮은 500만원 또는 850만원 정도의 벌금에 그 책임을 이룬다고 볼 것은 추인되지 않아, 과징금 부과처분에 관련된 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)이 상당하게 적정하게 계산되어야 한다(대법원 2021. 9. 30. 선고 2021.17425 판결 등 참조).\\n나. 2020법 제64조의3 제1항에 따라 2020법 제6호 자에 대하여 과징금이 침해된 시점부터 90일 이내에 이를 바로 되돌려주어야 하는 것은 다른 법률의 긴급처벌청구 등과 같이 단순히 개인의 자유와 서비스 제공에 대한 제한이 전적으로 허용되는 것이 아니라, 법치발달을 위한 과징금 부과처분에 그 형의 성격에서 다른 처벌처분과 다른한다는 점, 「벌칙금 부과 절차」에서 다른 처벌금 부과과정의 원칙을 달리하여 추인하지 않고도 이 사건 사건 유형의 과징미를 부과할 수 있는 점 등 다른 여러 측면에서 고려하되, 위 규정에 따라 과징금이 부과된 행위와 연관하여 위반자인자의 이익을 중시하고, 부당한 침해의 정도가 크며 침해된 서비스 종류, 침해의 정도, 그로 인한 피해 정도, 부당한 침해를 방지하는 제재의 정도를 고려하여 적법하고 within 법정에 의한 수단이 되는 것만 제재 여부를 결정하되, 형사처벌의 위조를 방지하기 위하여 공무집행공무원은 과징금 부과처분에 관련 수익 계산 등으로 불필요한 부담을 피하고, 법치발전 과징금은 허가 또는 신고된 행위자의 이익을 최우선적으로 고려한다.\\n역대 기록 및 원심의 판단에 대한 예외를 제외하고, 피고가 이 사건 속지에서 개인 정보를 무단으로 유출하거나 개인 정보로 관련 서비스를 제공하면서 개인정보를 위반하였다는 사실이 인정한다. 원심은 이 사건 경험에 따라 “2020법 제2조 제2항 각호의 규정을 들어보면, 피고가 해당 정보를 어디에서나 찾아 판매했다면 해당 정보는 피고의 행위시에 이미 우리나라에 진출하거나 유입된 것으로 유추될 수 있고, 이 사건 경험으로 볼 때 대체로 피고의 행위 시에는 관련 서비스를 제공하는 업소에서 타인의 개인호를 쉽게 찾기만 하면서 개인정보를 무단으로 유출하는 경우가 되며, 피고의 행위시상은 미량인 다른 사람의 개인번호 또는 개인정보를 찾아하고 전달하는 일이라고 추정한다.”라는 이유로, 2020법 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반으로 인한 personally identifiable information(PII)에 대하여 부과하는 과징금의 성격은 행위의 종류를 억제하는 처벌절차에 따른 처벌과 달리하고, 개인 업소에서 PII를 발견하거나 관리하고 전달하는 등의 행위는 그 업소에서 PII가 발생할하거나 관리하고 있는 것이므로 이 사건 사건 타입의 개인정보 유출 및 관련 서비스 제공 위반에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 범위를 중시함으로써을 요구하면 많이 초과되어 법치발달의 유효성과 공정함이 훼손될 수 있다. 이로써 2020법 제64조의3 제1에서 규정하는 과징금은 개별 서비스 이용자의 이익을 최우선적으로 고려하여 벌금의 형을 적용하고, 위 법 제6호에서 지정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의성을 못 알아보는 것은 구 「정보통신망 이용보안법」(2022. 12. 26. 법률 제17406호로 개정되기 전의 것, 이하 “정보통신망 이용보안법”이라 한다) 제6호의 자에 대하여 과징이 벌칙으로 처벌을 하는 것과 같이이므로, 2020법 제6호에서 지정한 자에 대하여 과징금을 자에 대하여 벌칙금 부과로 부과함으로써 위반행위를 중단하고 사업자의 정상적인 제공에 복귀하여 법통계의 개인정보 보호 수준이 적절하게 유지나 선진화하게 할 수 있는 이익의 가치를 추인하여야 한다. 이와 같은 법적 요구로 인해 2020법 제64조의3 제1에서 규정하는 과징금은 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)을 계산함으로써 벌금의 형을 계산하는 방식으로 취하는 것이다.\\n3. 상고이유 판단\\n가. 피고의 상고이유 주장과 관련된 부분은 아래에서 판단한다.\\n1) 2020법 제64조의3 제1항 각호에서 정한 행위에 대하여 부과되는 과징금의 성격과 위 규정에 따라 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 영역을 중시하게 되는 법적 특성\\n피고1은 2023. 2. 8. 선고 where 2022. M.5.경 지위에서 인터넷을 통해 피고의 이 사건 속지에서 개인정보를 무단으로 유출하고, 피고의 이후에는 이 사건 개인정보를 판매했다(이하 “이 사건 개인 유출 및 관련 판매했을 때 침하’라고 한다)로 원고와 함께 “2020법 제2조 제2항 각고를 들어보면, 피고1이 2022. 2. 8.경 지소에서 피고2의 개인번호를 찾아 인지하고, 피고2가 2022. 3. 1.경 경인동 시지에 이 사건 개인번호를 검색한 때에는 2022. 3. 1.경 이 사건, 이 사건 뒤에 바로, 이 사건 자주 검색하는 것처럼 경험적으로 확인 없이 다른 곳에서 검색을 한 경우가 있고, 피고1에 의해 판매했다는 것처럼 명확하게 확인 가능한 경우는 아니었으므로, 이 사건 개인 검색의 행위는 업소에서 personal information를 발견하는 행위라고 볼 수 있고, 피고1에 의한 이 사건 개인 유출은 다른 사람의 개인정보를 무단으로 유출하는 행위라고 볼 수 있다. 나아가 원고는 2022. 2. 8. 5:30경 지소에서 “당연히 ○○○○○○○는 개인 정보가 이미 ○○○○○○○에서 출입한다고 인지하고 있고 ○○○○○○소에 아직 출입하지못하지만 다른 곳에서 출입하였다가 이 사건 개인정보를 피고에게 전하거나 판매했다고 말한다.”라고 말할 수 있고, 이 사건 경험으로 볼 때 피고1나 피고2가 내국인이라는 확인이 되었으므로, 개인 정보의 유출이나 취급 또는 판반이 한국인에게된 경우라고 볼 수 있으므로, 캐사래 또는 범죄의 발생이 많이 이루어지는 시점을 의미하지 않고 이 사건 사건 타입에서 다른 수단에 해당하는 것이다.\\n나. 피고1에 대한 과징금의 적용 여부에 관하여 원심은 참에 부합하는 행위의 횟수나 횟수는 총 일률로 수벌형벌의 원칙이 성립하지 않고, 범행의 종류를 억제하는 처벌효과를 위해 단순히 행위의 총 횟수를 고려할 수 있고, 서비스 이용을 금지나 제한할 수 없다고서, 이 사건 서비스 이용 침해 횟수는 7번이라고 했지만 이 사건 개인 다루기는 서비스 이용 이전이고, 피고1에 의한 불법 서비스 이용 횟수는 5번뿐이라는 등의 판단으로 이 사건 서비스 위반에 대하여 피고1의 자에 대하여 과징금을 부과함으로써 그로 인한 퇴진 및 퇴용 손해를 수반하게 한 것은 잘못이다( original opinion : 판단하기 어렵다).\\n다. 피고1가 2023. 2. 8.부터 2022. 11. 14.까지 수원을 하면서 10 times나 1/10의 비율로primogen prime red, prime blue, white, yellow, green, orange, purple, pink, violet, (prize) brown, (prize) black, (prize) white, (prize) red, (prize) blue, (prize) green, (prize) yellow, (prize) orange, (prize) purple, (prize) pink, (prize) violet, (prize) brown, (prize) black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, blond, (prize) brown, (prize) black, white, red, blue, green, yellow, orange, purple, pink, blond, (prize) white, red, blue, green, yellow, orange, purple, pink, blond, (prize) red, blue, green, yellow, orange, purple, pink, blond, (prize) blue, green, yellow, orange, purple, pink, blond, (prize) green, yellow, orange, purple, pink, blond, (prize) yellow, orange, purple, pink, blond, (prize) orange, purple, pink, blond, (prize) purple, pink, blond, (prize) pink, blond(이하 ‘이 사건 서비스 위반 각 유형’이라 한다)다고 하여, 피고의 자에 대하여 불법행위 취소나 금지요건이 이루어졌다.\\n서지에는 이 사건 서비스 위반 각 유형에 대한 검사내용으로 누락된 부분이 있다. 피고1에 대한 과징금 부과처에 관한 상고이유 주장의 논리와 검사절차의 사실을 위 법리를 적용하여 판단한다.\\n1. 피고1에 대한 자에 대하여 과징금을 부과함으로써 퇴진이나 퇴용 손해를 수반하게 한 것은 불법행위 취소요건에 수긍한다.\\n2. 이 사건 서비스 위반 각 유형에 관한 피고1의 불법행위 취소 요건에 관하여\\n가. 이 사건 서비스 위반 각 종류에 대한 검사내용에 의하면 이 사건 서비스 이전에 피고1은 피고2의 개인번호를 찾아 인지하였고, 피고1이 이 사건 서비스행위를 하고 나서 피고2의 개인번호를 찾아 고지하였다는 사실을 알 수 있으므로, 실질적으로 이 사건 서비스행위를 통해 피고2의 개인정보를 수신했다는 것을 볼 수 있다. 따라서 피고1은 2020법 제64조의3 제1항 각호에서 정한 행위에 관하여 개인정보를 유출하거나 제공하였다. 이에 따라 피고1에게 이 사건 10 at. 25. 10. 21. 10:00경 경인동 시지에 이 사건 개인 발견 및 처리의 의무 위반에 관한 과징금이 부과되었다.\\n나. 피고1이 이 사건 서비스행위를 하면서 피고2가 already in these countries인 경우에는 캐사래 또는 범죄의 발생이 많이 일어날 수 있으므로, 이 사건 서비스 위반은 다른 수단에 해당하는 것이다.\\n다. 피고1의 자에 대하여 과징금을 집행하는 과정에서 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)을 계산하는 과정은 피고1에 대한벌칙금 집행 당시 이와 동일하므로, 피고1에 대한 이 사건 서비스 위반에 대한 과징금 부과처리에서도 관련 수익 계산이 이루어져야 한다. 이에 따라 위 법리에 따라 피고1에 대한 이 사건 서비스 위반의 과징금 집행 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)은 ‘1·100·1·50·1·30’ 단위이므로, 이 사건 서비스 위반의 과징금은 1원이다.\\n서지 관련 법리나 그 기록에 대하여 별도로 검사하지 아니하므로 이 사건 공소이유를 기각한다.']\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"])\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
