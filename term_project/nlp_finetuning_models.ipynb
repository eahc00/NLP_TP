{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pytorch_lightning\n",
    "from nlp_datasets import get_dataloader, get_dataset\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tensorboardX import SummaryWriter\n",
    "from accelerate import Accelerator\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "text_decoder_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    lagacy = False\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef07072816045a9831d6c8538c2842d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True, \n",
    "    quantization_config=bnb_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, module in base_model.named_modules():\n",
    "    print(name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[손해배상(기)]〈일제 강제동원 피해자들이 일본 기업을 상대로 불법행위로 인한 위자료 지급을 구하는 사건〉 [공2024상,204]\\n판시사항:[1] 객관적으로 채권자가 권리를 행사할 수 없는 장애사유가 있었던 경우, 채무자가 소멸시효 완성을 주장하는 것이 신의성실의 원칙에 반하는 권리남용에 해당하는지 여부(적극)\\n[2] 채권자에게 권리의 행사를 기대할 수 없는 객관적인 사실상의 장애사유가 있었으나 대법원이 채권자의 권리행사가 가능하다는 법률적 판단을 내린 경우, 그 시점 이후에는 장애사유가 해소되었다고 볼 수 있는지 여부(원칙적 적극)\\n[3] 일제강점기에 강제동원되어 기간 군수사업체인 구 미쓰비시중공업 주식회사에서 강제노동에 종사한 갑 등이 위 회사가 해산된 후 새로이 설립된 미쓰비시중공업 주식회사를 상대로 위자료 지급을 구한 사안에서, 강제동원 피해자의 일본 기업에 대한 위자료청구권은 ‘대한민국과 일본국 간의 재산 및 청구권에 관한 문제의 해결과 경제협력에 관한 협정’의 적용 대상에 포함되지 않는다는 법적 견해를 최종적으로 명확하게 밝힌 대법원 2018. 10. 30. 선고 2013다61381 전원합의체 판결이 선고될 때까지는 강제동원 피해자 또는 그 상속인들에게는 미쓰비시중공업 주식회사를 상대로 객관적으로 권리를 사실상 행사할 수 없는 장애사유가 있었다고 봄이 타당하다고 한 사례\\n\\n        assistant : \\n    ', 'label': '\\n그러므로 상고를 모두 기각하고 상고비용은 패소자가 부담하도록 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유(상고이유서 제출기간이 지난 후에 제출된 상고이유보충서의 기재는 상고이유를 보충하는 범위 내에서)를 판단한다.\\n1. 제1 상고이유에 대하여\\n원심은 판시와 같은 이유로 대한민국은 이 사건의 당사자 및 분쟁이 된 사안과 실질적 관련성이 있다고 할 것이어서 대한민국 법원이 이 사건에 대하여 국제재판관할권을 가진다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 국제재판관할에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n2. 제2 상고이유에 대하여\\n원심은 판시와 같은 이유를 들어 원고 1, 원고 2와 망 소외 1, 망 소외 2(이하 ‘원고 등’이라고 한다)를 노역에 종사하게 한 미쓰비시중공업 주식회사(이하 ‘구 미쓰비시중공업’이라고 한다)가 일본국 법률이 정한 바에 따라 해산되고 그 판시의 ‘제2회사’가 설립된 뒤 흡수합병의 과정을 거쳐 피고로 변경되는 등의 절차를 거쳤다고 하더라도, 구 미쓰비시중공업과 피고는 그 실질에 있어 동일성을 그대로 유지하고 있다고 보는 것이 타당하므로 원고 1, 원고 2, 원고 3과 망 소외 2(이하 ‘원고들’이라고 한다)는 구 미쓰비시중공업에 대한 이 사건 손해배상청구권을 피고에 대하여도 행사할 수 있다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 외국법인의 동일성 판단 기준 및 외국법 적용에 있어서의 공서양속 위반 여부에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n3. 제3 상고이유에 대하여\\n원심은, 「대한민국과 일본국 간의 재산 및 청구권에 관한 문제의 해결과 경제협력에 관한 협정」(이하 ‘청구권협정’이라고 한다)에 의하여 원고들의 피고에 대한 이 사건 손해배상청구권이 소멸하였는지에 관하여, 판시와 같은 이유를 들어, 원고들의 손해배상청구권은 일본 정부의 한반도에 대한 불법적인 식민지배 및 침략전쟁의 수행과 직결된 일본 기업의 반인도적인 불법행위를 전제로 하는 강제동원 피해자의 일본 기업에 대한 위자료청구권이라는 전제하에, 이러한 위자료청구권은 청구권협정의 적용 대상에 포함되었다고 볼 수 없다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 위와 같은 판단에 상고이유 주장과 같이 청구권협정의 적용 대상 및 효력에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 없다.\\n4. 제4 상고이유에 대하여\\n가. 채무자의 소멸시효를 이유로 한 항변권의 행사도 민법의 대원칙인 신의성실의 원칙과 권리남용금지의 원칙의 지배를 받는 것이어서 객관적으로 채권자가 권리를 행사할 수 없는 장애사유가 있었다면 채무자가 소멸시효 완성을 주장하는 것은 신의성실의 원칙에 반하는 권리남용으로서 허용될 수 없다(대법원 2011. 9. 8. 선고 2009다66969 판결 등 참조).\\n나. 원심은 피고의 소멸시효 완성 주장에 대해서 원고들이 이 사건 소를 제기한 2014. 2. 27. 무렵까지도 원고들에게는 객관적으로 손해배상청구권을 사실상 행사할 수 없는 장애사유가 있었다고 봄이 상당하다는 이유로 피고의 위 주장은 신의성실의 원칙에 반하는 권리남용으로 허용될 수 없다고 판단하였는바, 이 부분 원심판결의 이유를 위와 같은 법리와 기록에 비추어 살펴본다.\\n1) 채권자에게 권리의 행사를 기대할 수 없는 객관적인 사실상의 장애사유가 있었던 경우에도 대법원이 이에 관하여 채권자의 권리행사가 가능하다는 법률적 판단을 내렸다면 특별한 사정이 없는 한 그 시점 이후에는 그러한 장애사유가 해소되었다고 볼 수 있다.\\n2) 대법원은 2012. 5. 24. 선고한 2009다68620 판결 및 2009다22549 판결(이하 이를 합쳐 ‘2012년 판결’이라고 한다)에서 일제강점기에 강제동원된 피해자들의 일본 기업에 대한 불법행위를 이유로 한 손해배상청구권이 청구권협정의 적용 대상에 포함되지 않았다는 이유로 그 청구권이 소멸되지 않았다고 판단하였다.\\n3) 그러나 2012년 판결 선고 이후에도 청구권협정의 적용 대상에 강제동원 피해자들의 일본 기업에 대한 불법행위를 이유로 한 손해배상청구권이 포함되는지 여부 등에 관하여 여전히 국내외에서 논란이 계속되었고, 청구권협정의 당사자인 일본 정부는 청구권협정에 의하여 과거 일본 정부나 일본 기업 등이 관여한 반인도적 불법행위나 식민지배와 직결된 불법행위로 인한 손해배상청구권도 소멸되었다는 입장을 여전히 고수하였으며, 피고를 비롯한 일본 기업들도 이에 동조하면서 배상을 거부하였다. 이러한 상황에서 대한민국 정부는 남은 사법절차를 지켜보아야 한다는 것 외에 별다른 공식적인 입장표명은 하지 않았다.\\n4) 2012년 판결은 파기환송 취지의 판결로서 그로써 해당 사건 당사자들의 권리가 확정적으로 인정된 것이 아니었다. 또한 환송판결의 기속력도 환송 후 재판에서 새로 제출되는 주장과 증거에 따라 미치지 않을 수도 있었다(대법원 1988. 3. 8. 선고 87다카1396 판결 등 참조). 이러한 상황에서 원고 등과 같은 피해자들로서는 2012년 판결 선고 이후에도 개별적으로 일본 기업을 상대로 한 소송을 통해 실질적인 피해구제를 받을 수 있는지에 대하여 여전히 의구심을 가질 수 있었다.\\n5) 대법원은 2012년 판결 중 2009다68620 사건의 재상고심인 2013다61381 사건에서 2018. 10. 30. 전원합의체 판결(이하 ‘2018년 전원합의체 판결’이라고 한다)로써, 강제동원 피해자들의 일본 기업에 대한 불법행위를 이유로 한 위자료청구권이 청구권협정의 적용 대상에 포함되지 않았다고 판단한 후 같은 취지의 환송 후 원심의 판단을 유지하여 상고를 기각하였다. 이로써 대법원은 2018년 전원합의체 판결을 통해 일본 정부의 한반도에 대한 불법적인 식민지배 및 침략전쟁의 수행과 직결된 일본 기업의 반인도적인 불법행위를 전제로 하는 강제동원 피해자의 일본 기업에 대한 위자료청구권은 청구권협정의 적용 대상에 포함되지 않는다는 법적 견해를 최종적으로 명확하게 밝혔다.\\n6) 결국 2018년 전원합의체 판결 선고로 비로소 대한민국 내에서 강제동원 피해자들의 사법적 구제가능성이 확실하게 되었다고 볼 수 있다.\\n7) 이러한 사정을 고려할 때, 강제동원 피해자 또는 그 상속인인 원고들에게는 2018년 전원합의체 판결이 선고될 때까지는 피고를 상대로 객관적으로 권리를 사실상 행사할 수 없는 장애사유가 있었다고 봄이 상당하다.\\n다. 따라서 같은 취지의 원심의 위와 같은 판단에 상고이유 주장과 같이 소멸시효에 관한 법리 등을 오해하여 판결 결과에 영향을 미친 잘못이 없다.\\n5. 제5 상고이유에 대하여\\n불법행위로 입은 정신적 고통에 대한 위자료 액수에 관하여는 사실심 법원이 제반 사정을 참작하여 그 직권에 속하는 재량에 의하여 이를 확정할 수 있다(대법원 1999. 4. 23. 선고 98다41377 판결 등 참조).\\n원심은 판시와 같은 이유로 원고들에 대한 위자료 액수를 정하였다. 원심판결 이유를 기록에 비추어 살펴보면, 원심의 이 부분 판단에 상고이유 주장과 같이 위자료 산정에 관한 법리를 오해하는 등의 잘못이 없다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39a912ca8c444d7827e89c0fda8c732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[재산세부과처분취소]〈오피스텔을 주택으로 취급하여 재산세를 부과할 수 있는지 문제된 사건〉 [공2024상,64]\\n판시사항:오피스텔이 재산세 과세대상인 ‘주택’에 해당하는지 판단하는 기준\\n\\n        assistant : \\n    ', 'label': '\\n그러므로 상고를 기각하고 상고비용은 패소자가 부담하도록 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유를 판단한다.\\n1. 관련 법리\\n지방세법 제105조, 제104조 제2호, 제6조 제4호, 건축법 제2조 제1항 제2호, 제2항 및 그 위임에 따른 건축법 시행령 제3조의5 [별표 1] 제14호는 재산세 과세대상인 ‘건축물’ 중 일반업무시설의 하나로 ‘오피스텔(업무를 주로 하며, 분양하거나 임대하는 구획 중 일부 구획에서 숙식을 할 수 있도록 한 건축물로서 국토교통부장관이 고시하는 기준에 적합한 것을 말한다)’을 명시하였고, 지방세법 제105조, 제104조 제3호, 구 주택법(2021. 12. 21. 법률 제18631호로 개정되기 전의 것, 이하 같다) 제2조 제1호는 재산세 과세대상인 ‘주택’을 ‘세대의 구성원이 장기간 독립된 주거생활을 할 수 있는 구조로 된 건축물의 전부 또는 일부 및 그 부속토지’로 정하면서, 재산세 과세대상인 토지와 건축물의 범위에서 주택은 제외한다고 규정하였다.\\n구 지방세법 시행령(2021. 12. 31. 대통령령 제32293호로 개정되기 전의 것) 제119조는 ‘재산세의 과세대상 물건이 공부상 등재 현황과 사실상의 현황이 다른 경우에는 사실상 현황에 따라 재산세를 부과한다.’고 규정하였으므로, 재산세 과세대상인 ‘주택’에 해당하는지 여부는 특별한 사정이 없는 한 공부상의 용도에 관계없이 재산세 과세기준일 현재 사실상 주거용으로 사용되는지를 기준으로 판단함이 타당하다.\\n2. 판단\\n원심은, 원고가 이 사건 각 오피스텔을 「민간임대주택에 관한 특별법」에 따라 민간임대주택으로 등록한 후 주거용으로 임대한 사실 등 판시와 같은 사정을 인정한 다음, 이 사건 각 오피스텔의 공부상 등재 현황은 일반업무시설인 오피스텔이고, 구 주택법 및 그 시행령이 업무시설에 해당하는 오피스텔(업무를 주로 하며, 분양하거나 임대하는 구획 중 일부 구획에서 숙식을 할 수 있도록 한 건축물로서 국토교통부장관이 고시하는 기준에 적합한 것)을 준주택(주택 외의 건축물과 그 부속토지로서 주거시설로 이용가능한 시설 등)으로 분류하고 있더라도 사실상의 현황에 따라 주택으로 취급하여 재산세 등을 부과한 처분은 적법하다는 취지로 판단하였다.\\n원심판결 이유를 관련 규정과 법리, 기록에 비추어 살펴보면, 원심의 판단에 이 사건 각 오피스텔의 법적 성격에 관한 법리 등을 오해함으로써 판결에 영향을 미친 잘못이 없다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad196fee88df4fc795ab3e4410549d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = get_dataloader()\n",
    "valid_dataloader = get_dataloader(split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 8,172,867,584 || trainable%: 0.0577\n"
     ]
    }
   ],
   "source": [
    "## ---  LoRA --- ##\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    # modules_to_save=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    ")\n",
    "model = get_peft_model(base_model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "peft_model_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B_Lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "lr_scheduler = StepLR(optimizer, step_size=1, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerator.prepare(\n",
    "#     train_dataloader, valid_dataloader, model, optimizer, lr_scheduler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(output_filename, epoch, train_epoch_loss, train_epoch_ppl, val_epoch_loss, val_epoch_ppl):\n",
    "    metrics_data = {\n",
    "        \"epoch\" : epoch,\n",
    "        \"train_epoch_loss\": train_epoch_loss,\n",
    "        \"train_epoch_perplexity\": train_epoch_ppl,\n",
    "        \"val_epoch_loss\": val_epoch_loss,\n",
    "        \"val_epoch_perplexity\": val_epoch_ppl\n",
    "    }\n",
    "    with open(output_filename, \"a+\") as f:\n",
    "        json.dump(metrics_data, f)\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:36<00:00,  1.58it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(16.3460, device='cuda:0') train_epoch_loss=tensor(2.7940, device='cuda:0') eval_ppl=tensor(9.6034, device='cuda:0') eval_epoch_loss=tensor(2.2621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:39<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(8.1980, device='cuda:0') train_epoch_loss=tensor(2.1039, device='cuda:0') eval_ppl=tensor(7.0572, device='cuda:0') eval_epoch_loss=tensor(1.9540, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:39<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(6.0531, device='cuda:0') train_epoch_loss=tensor(1.8006, device='cuda:0') eval_ppl=tensor(5.5730, device='cuda:0') eval_epoch_loss=tensor(1.7179, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:39<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(4.6603, device='cuda:0') train_epoch_loss=tensor(1.5391, device='cuda:0') eval_ppl=tensor(4.4228, device='cuda:0') eval_epoch_loss=tensor(1.4868, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(3.6898, device='cuda:0') train_epoch_loss=tensor(1.3056, device='cuda:0') eval_ppl=tensor(3.5855, device='cuda:0') eval_epoch_loss=tensor(1.2769, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=tensor(2.9978, device='cuda:0') train_epoch_loss=tensor(1.0979, device='cuda:0') eval_ppl=tensor(3.0390, device='cuda:0') eval_epoch_loss=tensor(1.1115, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=tensor(2.5181, device='cuda:0') train_epoch_loss=tensor(0.9235, device='cuda:0') eval_ppl=tensor(2.5748, device='cuda:0') eval_epoch_loss=tensor(0.9458, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=tensor(2.1690, device='cuda:0') train_epoch_loss=tensor(0.7743, device='cuda:0') eval_ppl=tensor(2.2553, device='cuda:0') eval_epoch_loss=tensor(0.8133, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=tensor(1.9118, device='cuda:0') train_epoch_loss=tensor(0.6481, device='cuda:0') eval_ppl=tensor(1.9917, device='cuda:0') eval_epoch_loss=tensor(0.6890, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=tensor(1.7217, device='cuda:0') train_epoch_loss=tensor(0.5433, device='cuda:0') eval_ppl=tensor(1.7721, device='cuda:0') eval_epoch_loss=tensor(0.5722, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: train_ppl=tensor(1.5683, device='cuda:0') train_epoch_loss=tensor(0.4500, device='cuda:0') eval_ppl=tensor(1.6427, device='cuda:0') eval_epoch_loss=tensor(0.4964, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11: train_ppl=tensor(1.4579, device='cuda:0') train_epoch_loss=tensor(0.3770, device='cuda:0') eval_ppl=tensor(1.5216, device='cuda:0') eval_epoch_loss=tensor(0.4198, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12: train_ppl=tensor(1.3762, device='cuda:0') train_epoch_loss=tensor(0.3193, device='cuda:0') eval_ppl=tensor(1.4137, device='cuda:0') eval_epoch_loss=tensor(0.3462, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13: train_ppl=tensor(1.3043, device='cuda:0') train_epoch_loss=tensor(0.2657, device='cuda:0') eval_ppl=tensor(1.3487, device='cuda:0') eval_epoch_loss=tensor(0.2991, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14: train_ppl=tensor(1.2525, device='cuda:0') train_epoch_loss=tensor(0.2252, device='cuda:0') eval_ppl=tensor(1.2788, device='cuda:0') eval_epoch_loss=tensor(0.2459, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15: train_ppl=tensor(1.2110, device='cuda:0') train_epoch_loss=tensor(0.1914, device='cuda:0') eval_ppl=tensor(1.2406, device='cuda:0') eval_epoch_loss=tensor(0.2156, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16: train_ppl=tensor(1.1774, device='cuda:0') train_epoch_loss=tensor(0.1633, device='cuda:0') eval_ppl=tensor(1.1919, device='cuda:0') eval_epoch_loss=tensor(0.1755, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17: train_ppl=tensor(1.1520, device='cuda:0') train_epoch_loss=tensor(0.1415, device='cuda:0') eval_ppl=tensor(1.1664, device='cuda:0') eval_epoch_loss=tensor(0.1539, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18: train_ppl=tensor(1.1299, device='cuda:0') train_epoch_loss=tensor(0.1222, device='cuda:0') eval_ppl=tensor(1.1490, device='cuda:0') eval_epoch_loss=tensor(0.1389, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19: train_ppl=tensor(1.1115, device='cuda:0') train_epoch_loss=tensor(0.1057, device='cuda:0') eval_ppl=tensor(1.1217, device='cuda:0') eval_epoch_loss=tensor(0.1148, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20: train_ppl=tensor(1.0949, device='cuda:0') train_epoch_loss=tensor(0.0906, device='cuda:0') eval_ppl=tensor(1.0972, device='cuda:0') eval_epoch_loss=tensor(0.0927, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21: train_ppl=tensor(1.1008, device='cuda:0') train_epoch_loss=tensor(0.0961, device='cuda:0') eval_ppl=tensor(1.0902, device='cuda:0') eval_epoch_loss=tensor(0.0864, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22: train_ppl=tensor(1.0689, device='cuda:0') train_epoch_loss=tensor(0.0667, device='cuda:0') eval_ppl=tensor(1.0633, device='cuda:0') eval_epoch_loss=tensor(0.0614, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23: train_ppl=tensor(1.0768, device='cuda:0') train_epoch_loss=tensor(0.0740, device='cuda:0') eval_ppl=tensor(1.0727, device='cuda:0') eval_epoch_loss=tensor(0.0702, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24: train_ppl=tensor(1.0571, device='cuda:0') train_epoch_loss=tensor(0.0555, device='cuda:0') eval_ppl=tensor(1.0678, device='cuda:0') eval_epoch_loss=tensor(0.0656, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25: train_ppl=tensor(1.0597, device='cuda:0') train_epoch_loss=tensor(0.0580, device='cuda:0') eval_ppl=tensor(1.0530, device='cuda:0') eval_epoch_loss=tensor(0.0516, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26: train_ppl=tensor(1.0563, device='cuda:0') train_epoch_loss=tensor(0.0547, device='cuda:0') eval_ppl=tensor(1.0758, device='cuda:0') eval_epoch_loss=tensor(0.0730, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27: train_ppl=tensor(1.0442, device='cuda:0') train_epoch_loss=tensor(0.0433, device='cuda:0') eval_ppl=tensor(1.0343, device='cuda:0') eval_epoch_loss=tensor(0.0337, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28: train_ppl=tensor(1.0561, device='cuda:0') train_epoch_loss=tensor(0.0546, device='cuda:0') eval_ppl=tensor(1.0475, device='cuda:0') eval_epoch_loss=tensor(0.0464, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:38<00:00,  1.57it/s]\n",
      "100%|██████████| 91/91 [00:28<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29: train_ppl=tensor(1.0333, device='cuda:0') train_epoch_loss=tensor(0.0328, device='cuda:0') eval_ppl=tensor(1.0275, device='cuda:0') eval_epoch_loss=tensor(0.0271, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # print(batch)\n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.detach().float()\n",
    "        \n",
    "        # accelerator.backward(loss)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "    \n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(valid_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")\n",
    "    save_to_json(\"./finetuning_train_result.json\", epoch, float(train_epoch_loss), float(train_ppl.detach().cpu()), float(eval_epoch_loss), float(eval_ppl.detach().cpu()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eahc00/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(f\"./{peft_model_id}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fd4be523c445b7bca2d31778ec4876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\n",
      "        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\n",
      "        \n",
      " title:[손해배상(기)]〈일제 강제징용 노동자상을 제작·설치한 조각가 부부가 해당 노동자상의 모델이 일본인이라는 발언 등을 한 피고를 상대로 손해배상을 청구한 사건〉 [공2024상,97]\n",
      "판시사항:[1] 민법상 불법행위가 되는 ‘명예훼손’의 의미 / 순수한 의견 표명 자체만으로 명예훼손이 성립하는지 여부(소극) 및 어떠한 표현이 사실의 적시인지 의견의 진술인지 판단하는 기준\n",
      "[2] 명예훼손으로 인한 손해배상청구소송에서 적시된 사실의 허위성 및 위법성조각사유에 대한 증명책임의 분배\n",
      "[3] 일제 강제징용 피해자를 상징하는 강제징용 노동자상을 제작한 조각가 부부 갑 등이 위 노동자상은 조선인이 아니라 일본인들을 모델로 만들었다는 발언들을 한 시의회 의원 을을 상대로 허위사실 적시에 의한 명예훼손 등을 주장하며 손해배상을 구한 사안에서, 위 발언들은 통상적인 어휘의 의미나 전후 문맥 등 전체적인 흐름, 사회평균인의 지식이나 경험 등을 고려하여 그 표현의 의미를 확정할 경우 사실의 적시가 아니라 의견의 표명이나 구체적인 정황 제시가 있는 의혹의 제기에 불과하여 명예훼손의 불법행위에 해당하지 않는다고 볼 여지가 많고, 위 발언들이 진실한 사실에 기초한 것이 아니라고 하더라도 을로서는 위 발언들을 행할 당시 그 내용이 진실이라고 믿을 만한 상당한 이유가 있었다고 볼 여지가 많은데도, 이와 달리 본 원심판결에 법리오해 등의 잘못이 있다고 한 사례\n",
      "\n",
      "        assistant : \n",
      "    \n",
      "\n",
      "그러므로 원심판결 중 피고 패소 부분을 파기하고, 이 부분 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\n",
      "상고이유(상고이유서 제출기간이 지난 다음 제출된 서면의 기재는 상고이유를 보충하는 범위에서)를 판단한다.\n",
      "1. 사건의 경과\n",
      "원심판결 이유와 기록에 의하면 다음 사실을 알 수 있다.\n",
      "가. 조각가 부부인 원고들은 강제징용 노동자상 건립추진위원회의 의뢰를 받고 2016. 8. 24.부터 일제 강제징용 피해자를 상징하는 강제징용 노동자상을 제작하여 국내 각지에 설치해 왔고, 2019. 8. 13. ○○시청 앞 공원 광장에도 이 사건 노동자상을 설치하였다.\n",
      "나. ○○시의회 의원인 피고는 이 사건 노동자상과 관련하여 2019. 8. 12.부터 2019. 8. 14. 사이에 피고의 페이스북에 글을 게시하거나 보도자료를 배포하여, 위 노동자상은 조선인이 아니라 1920년대 일본 경찰의 수사로 구출된 일본인 강제노역 피해자들을 모델로 만들었으므로 이 사건 노동자상 설치는 역사왜곡 행위로서 허용될 수 없다는 등의 주장을 담은 이 사건 발언들을 하였다.\n",
      "2. 원심의 판단\n",
      "원심은 그 판시와 같은 이유로 이 사건 노동자상이 일본인을 모델로 하여 만들어졌다는 내용의 이 사건 발언들은 단순한 의견의 표명이 아니라 피해자를 원고들로 특정한 구체적 사실의 적시에 해당하고, 그 내용 또한 허위로 보이며, 피고가 이를 진실이라고 믿을 만한 상당한 이유가 없어 위법성이 조각되지 않는다고 판단하여, 피고의 명예훼손으로 인한 불법행위책임을 인정하였다.\n",
      "3. 대법원의 판단\n",
      "가. 민법상 불법행위가 되는 명예훼손이란 공연히 사실을 적시함으로써 사람의 품성, 덕행, 명성, 신용 등 인격적 가치에 대하여 사회적으로 받는 객관적인 평가를 침해하는 행위를 말한다. 타인의 사회적 평가를 침해할 가능성이 있을 정도로 구체성이 있는 사실을 명시적으로 적시한 표현행위가 명예훼손이 될 수 있음은 물론이지만, 의견이나 논평을 표명하는 형식의 표현행위도 그 전체적 취지에 비추어 의견의 근거가 되는 숨겨진 기초 사실에 대한 주장이 묵시적으로 포함되어 있고 그 사실이 타인의 사회적 평가를 침해할 수 있다면 명예훼손에 해당할 수 있다. 그러나 순수하게 의견만을 표명하는 경우 표현행위의 형식과 내용이 모욕적이고 경멸적인 인신공격에 해당하는 등 별개 유형의 불법행위를 구성할 수 있음은 별론으로 하고 그 의견 표명 자체만으로는 명예훼손이 성립하지 않는다. 여기서 어떠한 표현이 사실의 적시인지 의견의 진술인지는 어휘의 통상적인 의미나 전후 문맥 등 전체적인 흐름, 사회평균인의 지식이나 경험 등을 고려하여 그 표현의 진위를 결정하는 것이 가능한지 여부에 따라 판단되어야 한다(대법원 2002. 12. 24. 선고 2000다14613 판결, 대법원 2015. 9. 10. 선고 2013다26432 판결, 대법원 2018. 10. 30. 선고 2014다61654 전원합의체 판결 등 참조).\n",
      "한편 사실을 적시함으로써 타인의 명예를 훼손하는 경우 원고가 청구원인으로 그 적시된 사실이 허위사실이라고 주장하며 손해배상을 구하는 때에는 그 허위성에 대한 증명책임은 원고에게 있다. 다만 피고가 적시된 사실에 대하여 그 목적이 오로지 공공의 이익을 위한 것이고 그 내용이 진실한 사실이거나 진실이라고 믿을 만한 상당한 이유가 있어 위법성이 없다고 항변할 경우 위법성을 조각시키는 사유에 대한 증명책임은 이를 피고가 부담한다(대법원 2008. 1. 24. 선고 2005다58823 판결 등 참조).\n",
      "나. 원심판결 이유 및 기록에 의하여 알 수 있는 사실관계를 앞서 본 법리에 비추어 살펴본다.\n",
      "1) 먼저 이 사건 발언들은 통상적인 어휘의 의미나 전후 문맥 등 전체적인 흐름, 사회평균인의 지식이나 경험 등을 고려하여 그 표현의 의미를 확정할 경우 사실의 적시가 아니라 의견의 표명이나 구체적인 정황 제시가 있는 의혹의 제기에 불과하여 명예훼손의 불법행위에 해당하지 않는다고 볼 여지가 많고, 이를 허위라고 볼 만한 원고들의 증명 또한 충분하다고 보기 어렵다. 구체적인 이유는 다음과 같다.\n",
      "(1) 피고의 이 사건 발언들은 그 전체적인 맥락 등을 고려하면 이 사건 노동자상이 일본 내에서 강제노역을 하다가 구출된 일본인을 모델로 한 것이 아니냐는 의혹을 제기하거나 양자 간에 상호 유사성이 있다는 피고의 비판적 의견 표명으로 볼 여지가 있다.\n",
      "(2) 특히 이 사건 노동자상이 실제로 누구를 모델로 하였는지, 그로부터 얼마나 영향을 받았는지 여부는 제작자인 원고들의 내심의 의사에 기반한 창작 결과물만을 보는 제3자로서는 이를 알 수가 없는 것이고, 그 진위를 증거에 의하여 증명할 수 있는 영역이라고 보기도 어렵다.\n",
      "(3) 예술작품이 어떠한 형상을 추구하고 어떻게 보이는지는 그 작품이 외부에 공개되는 순간부터 감상자의 주관적인 평가의 영역에 놓여 그에 따른 비평의 대상이 된다. 예술작품에 대한 개인적·심미적 취향의 표현이나 특정 대상과 비교하는 등의 비평은 그 자체로 모욕적이고 경멸적인 인신공격에 해당하여 타인의 인격권을 침해하는 등 별도의 불법행위를 구성하는 정도에 이르지 않는다면 섣불리 이를 구체적인 사실의 적시로서 명예훼손의 성립요건을 충족한다고 평가하는 것에 신중할 필요가 있다.\n",
      "2) 나아가 아래에서 보는 바와 같이 피고가 이 사건 노동자상에 대한 의혹의 제기나 주장을 진실이라고 믿을 만한 상당한 이유를 인정할 여지도 있어 보인다.\n",
      "(1) 이 사건 발언들은 공적 공간에 설치되어 그 철거 여부에 대한 사회적 관심을 불러일으키고 일제 강제징용과 관련된 공론을 이끌어낸 이 사건 노동자상을 대상으로 한 것이라는 점에서 공공의 이익과 관련된 것으로 볼 수 있다.\n",
      "(2) 그런데 기록에 의하여 알 수 있는 사정, 즉 위 노동자상과 유사하다고 지목된 일본인들의 사진은 실제로 상당 기간 국내 초·중·고교 교과서나 부산 소재 국립일제강제동원역사관 내 설치물에 조선인 강제징용 노동자로서 소개된 바 있었던 점, 그러다가 이 사건 노동자상의 설치 전부터 언론보도를 통해 위 사진 속 인물들이 사실은 조선인이 아닌 일본인이라는 것이 알려지기 시작한 점, 그 후로 해당 교과서나 역사관 내 사진이 순차 교체되거나 삭제되기에 이른 점 등에 비추어, 설혹 이 사건 발언들이 진실한 사실에 기초한 것이 아니라고 하더라도 피고로서는 위 발언들을 행할 당시 그 내용이 진실이라고 믿을 만한 상당한 이유가 있었다고 볼 여지가 많다.\n",
      "다. 그럼에도 원심이 판시와 같은 이유를 들어 이 사건 발언들을 허위사실의 적시로 단정하고, 위법성이 없다는 피고의 항변을 배척하여 명예훼손으로 인한 불법행위책임을 인정한 것에는 명예훼손에서의 사실의 적시, 허위성의 증명 및 위법성조각사유에 관한 법리를 오해하거나 논리와 경험의 법칙을 위반하여 자유심증주의의 한계를 벗어남으로써 판결에 영향을 미친 잘못이 있다. 이를 지적하는 상고이유 주장은 이유 있다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "text_decoder_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "peft_model_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B_Lora\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# LoRA 적용 모델 불러오기\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True, \n",
    "    quantization_config=bnb_config\n",
    "    )\n",
    "\n",
    "\n",
    "load_model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "loaded_state_dict = load_file(\"/home/eahc00/NLP/term_project/MLP-KTLim/llama-3-Korean-Bllossom-8B_Lora/adapter_model.safetensors\")\n",
    "load_model.load_state_dict(loaded_state_dict, strict=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decoder_id)\n",
    "\n",
    "ds = get_dataset(split=\"valid\", get_prompt_only=True)\n",
    "\n",
    "load_model.to('cuda')\n",
    "\n",
    "i = 1\n",
    "inputs = tokenizer(ds[i]['prompt'], return_tensors=\"pt\")\n",
    "print(ds[i]['prompt'])\n",
    "print(ds[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:144783 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n        system : 한국말로만 대답하고 최대한 간결하고 알기쉽게 정리해줘.\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[손해배상(기)]〈일제 강제징용 노동자상을 제작·설치한 조각가 부부가 해당 노동자상의 모델이 일본인이라는 발언 등을 한 피고를 상대로 손해배상을 청구한 사건〉 [공2024상,97]\\n판시사항:[1] 민법상 불법행위가 되는 ‘명예훼손’의 의미 / 순수한 의견 표명 자체만으로 명예훼손이 성립하는지 여부(소극) 및 어떠한 표현이 사실의 적시인지 의견의 진술인지 판단하는 기준\\n[2] 명예훼손으로 인한 손해배상청구소송에서 적시된 사실의 허위성 및 위법성조각사유에 대한 증명책임의 분배\\n[3] 일제 강제징용 피해자를 상징하는 강제징용 노동자상을 제작한 조각가 부부 갑 등이 위 노동자상은 조선인이 아니라 일본인들을 모델로 만들었다는 발언들을 한 시의회 의원 을을 상대로 허위사실 적시에 의한 명예훼손 등을 주장하며 손해배상을 구한 사안에서, 위 발언들은 통상적인 어휘의 의미나 전후 문맥 등 전체적인 흐름, 사회평균인의 지식이나 경험 등을 고려하여 그 표현의 의미를 확정할 경우 사실의 적시가 아니라 의견의 표명이나 구체적인 정황 제시가 있는 의혹의 제기에 불과하여 명예훼손의 불법행위에 해당하지 않는다고 볼 여지가 많고, 위 발언들이 진실한 사실에 기초한 것이 아니라고 하더라도 을로서는 위 발언들을 행할 당시 그 내용이 진실이라고 믿을 만한 상당한 이유가 있었다고 볼 여지가 많은데도, 이와 달리 본 원심판결에 법리오해 등의 잘못이 있다고 한 사례\\n\\n        assistant : \\n    \\n그러므로 원심판결 중 피고 패소 부분을 파기하고, 이 부분 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유(상고이유서 제출기간이 지난 다음 제출된 서면의 기재는 상고이유를 보충하는 범위에서)를 판단한다.\\n1. 사건의 경과\\n원심판결 이유와 기록에 의하면 다음 사실을 알 수 있다.\\n가. 조각가 부부인 원고들은 강제징용 노동자상 건립추진위원회의 의뢰를 받고 2016. 8. 24.부터 일제 강제징용 피해자를 상징하는 강제징용 노동자상을 제작하여 국내 각지에 설치해 왔고, 2019. 8. 13. ○○시청 앞 공원 광장에도 이 사건 노동자상을 설치하였다.\\n나. ○○시티 ○○평가는 2019. 8. 12. 이 사건 노동자상 설치 중 피고와 원고들을 감시·점검하는 기능을 맡는 ○○시티 forced징용보상정책과를 개설하고, 원고들이 강제징용 노동자상을 일본 style으로 설치하고 있음을 사실을 바탕으로 피고와 그 기관에 인지·전매하는 one-one-one 대화 및 광고로서 이 사건 노동자상은 일본식이며, 일본 사람들 모델인 이 사건 노동자상이 역사적 배경과 그 역사적 배경에 따른 한국인들의 인식 등에 영향을 받을 수 있는 이유 등 여러 가지 이유로 그렇게 해야 한다는 내용의 C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·C·']\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = load_model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=512)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
