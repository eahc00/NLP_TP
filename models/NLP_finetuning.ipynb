{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset_dir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlp_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloader, get_dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset_dir'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pytorch_lightning\n",
    "from nlp_datasets import get_dataloader, get_dataset\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "text_decoder_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    lagacy = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22208625530c4270add8b8aa7ee29583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    text_decoder_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True, \n",
    "    quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.layers.28\n",
      "model.layers.28.self_attn\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.self_attn.rotary_emb\n",
      "model.layers.28.mlp\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.28.mlp.act_fn\n",
      "model.layers.28.input_layernorm\n",
      "model.layers.28.post_attention_layernorm\n",
      "model.layers.29\n",
      "model.layers.29.self_attn\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.self_attn.rotary_emb\n",
      "model.layers.29.mlp\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.29.mlp.act_fn\n",
      "model.layers.29.input_layernorm\n",
      "model.layers.29.post_attention_layernorm\n",
      "model.layers.30\n",
      "model.layers.30.self_attn\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.self_attn.rotary_emb\n",
      "model.layers.30.mlp\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.30.mlp.act_fn\n",
      "model.layers.30.input_layernorm\n",
      "model.layers.30.post_attention_layernorm\n",
      "model.layers.31\n",
      "model.layers.31.self_attn\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.self_attn.rotary_emb\n",
      "model.layers.31.mlp\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "model.layers.31.mlp.act_fn\n",
      "model.layers.31.input_layernorm\n",
      "model.layers.31.post_attention_layernorm\n",
      "model.norm\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for name, module in base_model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[보수약정금]〈북한주민인 피고들과 위임 및 보수약정을 체결한 법무법인인 원고가 위임약정에 따른 업무 수행 후 피고들을 상대로 성공보수금을 청구한 사건〉 [공2024상,727]\\n판시사항:[1] 북한주민이 상속 등으로 취득한 재산 그 자체는 물론이고 그 재산을 처분한 대가로 얻은 재산을 처분하는 행위 역시 남북 주민 사이의 가족관계와 상속 등에 관한 특례법 제15조에 따라 재산관리인을 통하지 않은 경우, 무효인지 여부(적극) 및 그러한 법률행위가 재산관리인이 선임되기 전에 있었다고 하더라도 마찬가지인지 여부(적극)\\n[2] 일부무효의 법리를 정한 민법 제137조에서 ‘당사자의 의사’의 의미 / 여러 개의 계약 전부가 경제적, 사실적으로 일체로서 행하여져서 하나의 계약인 것과 같은 관계에 있는 경우, 법률행위의 일부무효 법리가 적용되는지 여부(적극)\\n[3] 변호사에게 계쟁 사건의 처리를 위임하는 경우, 보수 지급 및 수액에 관하여 명시적인 약정을 아니하였더라도 보수를 지급할 묵시의 약정이 있는 것으로 보아야 하는지 여부(원칙적 적극) 및 이 경우 보수액을 결정하는 방법\\n[4] 갑 법무법인이 남북 주민 사이의 가족관계와 상속 등에 관한 특례법의 적용을 받는 북한주민인 을 등과 을 등의 병에 대한 친생자확인소송, 상속회복 청구소송 등에 관한 위임약정 및 ‘총상속지분의 30% 또는 이에 상응하는 금전’을 성공보수로 받는 보수약정을 체결하였고, 이후 병의 상속인들 사이에 화해가 성립하여 을 등이 상속재산을 분할받자, 갑 법무법인이 을 등을 상대로 위 보수약정에 따라 상속재산 30%에 해당하는 돈의 지급을 구하였으나, 을 등이 위 보수약정은 재산관리인을 통하지 아니하고 상속재산 등에 관하여 한 법률행위이므로, 위 특례법 제15조에 따라 무효라고 주장한 사안에서, 제반 사정에 비추어 위 보수약정이 무효로 된다고 하더라도 양 당사자는 위 위임계약을 체결, 유지하려는 가정적 의사가 있었다고 볼 여지가 있고, 응분의 보수를 지급할 묵시의 약정이 있는 것으로 볼 수 있다고 한 사례\\n\\n    ', 'label': '\\n원심판결을 파기하고, 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유(상고이유서 제출기간이 지난 다음 제출된 상고이유보충서의 기재는 상고이유를 보충하는 범위에서)를 판단한다.\\n1. 사안의 개요\\n원심판결 이유와 기록에 의하면 다음 사실을 알 수 있다.\\n가. 원고는 변호사의 직무에 속하는 업무 등 법률서비스를 제공하는 법무법인이고, 피고들은 「남북 주민 사이의 가족관계와 상속 등에 관한 특례법」(이하 ‘남북가족특례법’이라 한다)에 따른 북한주민이다.\\n나. 망 소외 2는 2012. 3. 17.경 사망하였고, 망 소외 2의 상속인은 2013. 4. 22. 다른 상속인들을 상대로 상속재산분할심판(서울가정법원 2013느합102, 이하 ‘이 사건 상속재산분할심판’이라 한다)을 청구하였다.\\n다. 피고들은 2015년경 망 소외 3에게 피고들의 망 소외 2에 대한 상속재산 일체에 관한 처분 및 관리, 변호사 선임, 소송 권한 등을 위임하였고, 피고들로부터 위 권한을 위임받은 망 소외 3은 2016년 초경 원고와 친생자확인소송, 상속회복 청구소송 등에 관한 위임약정(이하 ‘이 사건 위임약정’이라 한다) 및 보수약정(이하 ‘이 사건 보수약정’이라 한다)을 체결하였다.\\n라. 이 사건 위임약정 및 보수약정에 따르면, 수임인이 소송이나 화해, 합의 등을 통하여 분쟁을 해결한 경우 위임인은 수임인에게 성공보수를 지급해야 하는데, 성공보수는 ‘총상속지분의 30% 또는 이에 상응하는 금전’으로 하고, 친생자확인 및 상속회복 청구소송 등의 결과로 수령하는 돈에서 성공보수를 먼저 지급하여야 한다.\\n마. 원고는 2016. 4. 15. 피고들을 대리하여 친생자관계존재 확인청구(서울가정법원 2016드단310391)를 하였고, 서울가정법원은 2018. 5. 25. 피고들과 망 소외 2 사이에 친생자관계가 존재한다는 내용의 판결을 선고하였다. 원고는 위 소송의 항소심(서울가정법원 2018르31102)에서도 피고들을 대리하였고, 위 소송은 2018. 8. 22. 항소 취하로 확정되었다.\\n바. 서울가정법원은 2016. 8. 12. 이 사건 상속재산분할심판 사건에서 일부인용 결정을 하였다. 원고는 2016. 10. 5. 위 사건의 항소심(서울고등법원 2016브41, 42)에서 피고들을 대리하여 필수적 공동소송인 추가신청서와 보조참가신청서 등을 제출하였고, 2017. 9. 28. 당사자추가신청서, 공동소송참가신청서, 증거(유전자검사결과에 관한 감정서) 등을 제출하였다. 위 사건의 항소심 재판부는 피고들의 참가신청을 받아들였고, 2019. 2. 14. 피고들을 비롯한 망 소외 2의 상속인들 사이에 화해가 성립하였다.\\n사. 원고는 위 화해에 따른 피고들의 상속지분 평가액이 각 19,624,266,000원 상당이라고 주장하면서 이 사건 보수약정에 따라 그 30%에 상응하는 돈의 지급을 구하는 이 사건 소송을 제기하였다.\\n2. 이 사건 보수약정의 무효 여부에 관한 판단(제2 상고이유)\\n남북가족특례법 제15조 본문은 “재산관리인을 통하지 아니하고 상속·유증재산 등에 관하여 한 법률행위는 무효로 한다.”라고 규정하고 있고, 남북가족특례법상 ‘상속·유증재산 등’은 상속 등으로 취득한 북한주민의 남한 내 재산과 상속·유증 받은 재산 등의 과실 또는 대가로 얻은 재산을 포함한다(남북가족특례법 제13조 제1항). 위와 같은 규정과 북한주민이 취득한 남한 내 재산이 북한으로 유출되어 다른 용도로 전용되는 것을 방지하고자 하는 남북가족특례법상의 북한주민 상속·수증재산 등 관리제도의 입법 목적 등을 고려하면, 북한주민이 상속 등으로 취득한 재산 그 자체는 물론이고 그 재산을 처분한 대가로 얻은 재산을 처분하는 행위 역시 남북가족특례법 제15조에 따라 재산관리인을 통하지 않으면 무효이고, 그러한 법률행위가 재산관리인이 선임되기 전에 있었다고 하더라도 마찬가지라고 보아야 한다.\\n원심은, 판시와 같은 이유로 이 사건 보수약정이 남북가족특례법 제15조에 따라 무효이고, 피고들 재산관리인이 위 법 제15조에 따라 이 사건 보수약정의 무효를 주장하는 것이 정의관념에 비추어 용인될 수 없는 정도의 상태에 이르렀다고 단정하기 어렵다고 판단한 제1심판결을 그대로 유지하였다. 원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 판단에 남북가족특례법 제15조의 해석에 관한 법리를 오해한 잘못이 없다.\\n3. 이 사건 위임약정의 무효 여부에 관한 판단(제1 상고이유)\\n가. 법률행위의 일부분이 무효인 때에는 그 전부를 무효로 하나, 그 무효 부분이 없더라도 법률행위를 하였을 것이라고 인정될 때에는 나머지 부분은 무효가 되지 아니한다(민법 제137조). 여기서 당사자의 의사는 법률행위의 일부가 무효임을 법률행위 당시에 알았다면 의욕하였을 가정적 효과의사를 가리키는 것이다. 그리고 이와 같은 법률행위의 일부무효 법리는 여러 개의 계약이 체결된 경우에 그 계약 전부가 경제적, 사실적으로 일체로서 행하여져서 하나의 계약인 것과 같은 관계에 있는 경우에도 적용된다(대법원 2023. 2. 2. 선고 2019다232277 판결 등 참조).\\n변호사에게 계쟁 사건의 처리를 위임하는 경우에 그 보수 지급 및 수액에 관하여 명시적인 약정을 아니하였더라도, 무보수로 한다는 등 특별한 사정이 없는 한 응분의 보수를 지급할 묵시의 약정이 있는 것으로 봄이 상당하고, 이 경우 그 보수액은 사건 수임의 경위, 사건의 경과와 난이 정도, 소송물 가액, 승소로 인하여 당사자가 얻는 구체적 이익, 의뢰인과 변호사 간의 관계, 기타 변론에 나타난 여러 사정을 참작하여 결정함이 상당하다(대법원 1995. 12. 5. 선고 94다50229 판결 등 참조).\\n나. 원심은, 이 사건 위임약정과 보수약정은 경제적, 사실적으로 일체로서 행하여져서 그 전부가 하나의 계약인 것과 같은 관계에 있고, 원고로서는 이 사건 보수약정이 무효로 된다면 무보수로 이 사건 위임약정을 하지는 않았을 것이라는 이유로, 이 사건 보수약정이 남북가족특례법에 위반되어 무효로 되는 이상 이 사건 위임약정도 민법 제137조에 의하여 무효라고 판단하였다.\\n다. 그러나 원심의 위와 같은 판단은 다음과 같은 이유로 수긍하기 어렵다.\\n원심은 이 사건 보수약정이 무효라면 이 사건 위임약정은 무상의 위임계약이 된다는 점을 전제로 하고 있다. 그러나 보수약정이 무효라고 하여 곧바로 이 사건 위임약정이 무상의 위임계약이 된다고 단정할 수는 없고, 단지 보수 지급 및 수액에 관하여 명시적인 약정이 없는 경우에 해당할 뿐이다. 이러한 경우, 다음과 같은 사정을 앞서 본 법리에 비추어 보면 원고와 피고들 사이에는 응분의 보수를 지급할 묵시의 약정이 있는 것으로 볼 수 있다.\\n먼저, 북한주민인 피고들로서는 아무런 보수를 지급하지 않고서 원고에게 사건을 위임하겠다는 의사가 있었다기보다는, 원고에게 어느 정도의 보수를 지급할 의사가 있었다고 보일 뿐만 아니라, 남한 내 상속재산을 회복하기 위해서는 원고와의 위임계약이 필요한 상황이었으므로, 이 사건 보수약정이 무효가 된다는 사정을 알았더라도 이 사건 위임계약을 체결할 의사가 있었다고 보는 것이 타당하다.\\n다음으로, 피고들의 상황과 남한 내 상속재산의 규모 등을 고려하면, 법무법인인 원고로서는 이 사건 보수약정이 무효라는 사정을 알았더라도 추후 선임될 재산관리인을 통하여 보수약정을 체결하는 것이 가능한 이상, 보수약정 없이 먼저 위임계약만을 체결하는 것을 용인할 의사가 있었을 것으로 추단할 수 있다. 결국 이 사건 보수약정이 무효로 된다고 하더라도 양 당사자는 이 사건 위임계약을 체결, 유지하려는 가정적 의사가 있었다고 볼 여지가 있다.\\n라. 그런데도 원심은 원고가 무보수로 이 사건 위임약정을 하지는 않았을 것이라는 이유로 이 사건 보수약정과 함께 이 사건 위임약정도 무효가 된다고 판단하였다. 이러한 원심판단에는 민법 제137조의 일부무효에 관한 법리를 오해하여 판결에 영향을 미친 잘못이 있다. 이 점을 지적하는 취지의 원고의 상고이유 주장은 이유 있다.\\n한편 환송 후 원심으로서는 이 사건 보수약정이 무효라고 하더라도 위임약정이 유효한 이상, 위임약정에 따른 보수액은 사건 수임의 경위, 사건의 경과와 난이 정도, 소송물 가액, 승소로 인하여 당사자가 얻는 구체적 이익, 의뢰인과 변호사 간의 관계, 기타 변론에 나타난 여러 사정을 참작하여 결정하여야 한다는 점을 미리 지적하여 둔다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1e7ebd0b3b475491f9ac154b97440d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict:  {'prompt': '\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[손해배상(기)]〈업무집행지시자 등을 상대로 회사에 대한 손해배상을 구하는 사건〉 [공2023하,2059]\\n판시사항:[1] 상법 제399조 제1항, 제414조 제1항에서 규정하고 있는 주식회사의 이사 또는 감사의 회사에 대한 임무 해태로 인한 손해배상책임에 따른 손해배상채권에 민법 제766조 제1항의 단기소멸시효가 적용되는지 여부(소극)\\n[2] 상법 제401조의2 제1항에서 정한 업무집행지시자 등의 손해배상책임에 따른 손해배상채권에 일반 불법행위책임의 단기소멸시효를 규정한 민법 제766조 제1항이 적용되는지 여부(소극)\\n\\n    ', 'label': '\\n그러므로 상고를 모두 기각하고, 상고비용은 패소자가 부담하도록 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유(상고이유서 제출기간이 지난 다음 제출된 서면 기재는 상고이유를 보충하는 범위에서)를 판단한다.\\n1. 사안의 개요\\n원심판결 이유와 기록에 따르면 다음 사실을 알 수 있다.\\n가. ○○○호텔 주식회사는 호텔, 콘도 관리 및 운영업 등을 영위하는 회사로서 2007년경부터 ○○○호텔의 구분소유자들로부터 권한을 위탁받아 위 호텔을 운영하였다. 위 회사에 대하여 2018. 3. 16. 파산이 선고되었고(부산지방법원 2017하합4호), 원고가 위 회사의 파산관재인으로 선임되었다(이하 ○○○호텔 주식회사를 ‘파산회사’라고 한다).\\n나. 피고 1은 2004. 2. 25.부터 2004. 12. 1.까지는 파산회사의 대주주로서 공동대표이사, 2007. 5. 18.부터 2008. 8. 5.까지는 파산회사의 이사로 재직하였고, 이후 2016. 5. 18.까지 파산회사의 회장으로서 실제 전반적인 운영을 담당하였다. 피고 2는 2006. 8. 2.부터 2016. 5. 18.까지 파산회사의 대표이사로 재직하였고, 피고 3은 2007. 5. 18.부터 2008. 8. 5.까지는 파산회사의 감사, 2008. 8. 5.부터 2016. 5. 18.까지는 파산회사의 이사로 재직하였다.\\n다. 피고들은 파산회사에 대한 업무상횡령죄 등으로 기소되어 일부 횡령 범행에 관하여 유죄판결을 선고받았고 2016. 5. 24. 그 유죄판결이 확정되었다.\\n2. 소멸시효에 관한 상고이유에 대한 판단\\n가. 피고 2, 피고 3의 상고이유에 관하여\\n상법 제399조 제1항, 제414조 제1항에서 규정하고 있는 주식회사의 이사 또는 감사의 회사에 대한 임무 해태로 인한 손해배상책임은 위임관계로 인한 채무불이행책임이므로 그에 따른 손해배상채권에는 민법 제766조 제1항의 단기소멸시효가 적용되지 않는다고 보아야 한다(대법원 1985. 6. 25. 선고 84다카1954 판결, 대법원 2008. 12. 11. 선고 2005다51471 판결 등 참조).\\n원심이 판시와 같은 이유로 원고의 예비적 청구(상법 제399조 제1항에 의한 손해배상채권)에 대한 피고 2, 피고 3의 단기소멸시효 항변을 배척한 것은 정당하고, 거기에 상법 제399조 제1항에 의한 손해배상책임의 성질 및 소멸시효 기간에 관한 법리를 오해한 잘못이 없다.\\n나. 피고 1의 상고이유에 관하여\\n1) 상법 제401조의2 제1항은 회사에 대한 자신의 영향력을 이용하여 이사에게 업무집행을 지시한 자(제1호), 이사의 이름으로 직접 업무를 집행한 자(제2호) 또는 이사가 아니면서 명예회장·회장·사장·부사장·전무·상무·이사 기타 회사의 업무를 집행할 권한이 있는 것으로 인정될 만한 명칭을 사용하여 회사의 업무를 집행한 자(제3호)가 그 지시하거나 집행한 업무에 관하여 제399조, 제401조, 제403조 및 제406조의2를 적용하는 경우에는 그 자를 “이사”로 본다고 규정하고 있다. 이는 주식회사의 이사가 아니지만 이사에게 업무집행을 지시하거나 이사처럼 업무를 집행하는 등으로 회사의 업무에 관여한 자에 대하여 그에 상응하는 책임을 묻기 위함이다.\\n이러한 법률 문언 내용과 입법 취지에 비추어 보면, 상법 제401조의2 제1항 각호에 해당하는 자는 회사의 이사는 아니지만 상법 제399조에서 정한 손해배상책임을 적용함에 있어 그가 관여한 업무에 관하여 법령준수의무를 비롯하여 이사와 같은 선관주의의무와 충실의무를 부담하고, 이를 게을리하였을 경우 회사에 대하여 그로 인한 손해배상책임을 지게 되는 것이다. 이와 같이 상법 제401조의2 제1항이 정한 손해배상책임은 상법에 의하여 이사로 의제되는 데 따른 책임이므로 그에 따른 손해배상채권에는 일반 불법행위책임의 단기소멸시효를 규정한 민법 제766조 제1항이 적용되지 않는다.\\n2) 원심은 피고 1의 상법 제401조의2 제1항 제1호, 제3호, 제399조 제1항에 따른 손해배상채권에 관한 소멸시효 항변을 받아들이지 않았다.\\n원심판결 이유를 앞서 본 법리와 기록에 비추어 살펴보면, 원심의 이러한 판단은 정당하고, 거기에 상고이유 주장과 같이 상법 제401조의2 제1항, 제399조 제1항에 따른 손해배상책임의 성질과 소멸시효에 관한 법리를 오해한 잘못이 없다.\\n3. 상계합의 또는 상계 항변, 손해배상책임의 면책 내지 면제 주장에 관한 상고이유에 대한 판단\\n원심은 피고들의 손해배상책임의 존재를 전제로 피고들의 파산회사에 대한 위탁수수료 채권은 인정되지 않는다고 보아 피고들의 상계합의 또는 상계 항변을 배척하였고, 피고들에게 손해배상책임이 있다고 판단하였다.\\n원심판결 이유를 관련 법리와 기록에 비추어 살펴보면, 원심의 이러한 판단은 정당하고, 거기에 상고이유 주장과 같이 법률행위 해석, 상계 항변 등에 관한 법리를 오해하거나 석명권 행사를 게을리하고 필요한 심리를 다하지 않은 채 논리와 경험의 법칙을 위반하여 자유심증주의의 한계를 벗어나는 등으로 결론에 영향을 미친 잘못이 없다.\\n'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe60f202eaf94366b9d1ee5439af2a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = get_dataloader()\n",
    "valid_dataloader = get_dataloader(split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 8,172,867,584 || trainable%: 0.0577\n"
     ]
    }
   ],
   "source": [
    "## ---  LoRA --- ##\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "model = get_peft_model(base_model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "peft_model_id = f\"MLP-KTLim/llama-3-Korean-Bllossom-8B_Lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "lr_scheduler = StepLR(optimizer, step_size=1, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:24<00:00,  1.62it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(16.1834, device='cuda:0') train_epoch_loss=tensor(2.7840, device='cuda:0') eval_ppl=tensor(10.2516, device='cuda:0') eval_epoch_loss=tensor(2.3274, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:25<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(8.0611, device='cuda:0') train_epoch_loss=tensor(2.0870, device='cuda:0') eval_ppl=tensor(7.5395, device='cuda:0') eval_epoch_loss=tensor(2.0202, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(5.9484, device='cuda:0') train_epoch_loss=tensor(1.7831, device='cuda:0') eval_ppl=tensor(6.0085, device='cuda:0') eval_epoch_loss=tensor(1.7932, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(4.5823, device='cuda:0') train_epoch_loss=tensor(1.5222, device='cuda:0') eval_ppl=tensor(4.8067, device='cuda:0') eval_epoch_loss=tensor(1.5700, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(3.6450, device='cuda:0') train_epoch_loss=tensor(1.2934, device='cuda:0') eval_ppl=tensor(3.9433, device='cuda:0') eval_epoch_loss=tensor(1.3720, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=tensor(2.9727, device='cuda:0') train_epoch_loss=tensor(1.0895, device='cuda:0') eval_ppl=tensor(3.2885, device='cuda:0') eval_epoch_loss=tensor(1.1904, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=tensor(2.4979, device='cuda:0') train_epoch_loss=tensor(0.9154, device='cuda:0') eval_ppl=tensor(2.8077, device='cuda:0') eval_epoch_loss=tensor(1.0324, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=tensor(2.1617, device='cuda:0') train_epoch_loss=tensor(0.7709, device='cuda:0') eval_ppl=tensor(2.4375, device='cuda:0') eval_epoch_loss=tensor(0.8910, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=tensor(1.9085, device='cuda:0') train_epoch_loss=tensor(0.6463, device='cuda:0') eval_ppl=tensor(2.1308, device='cuda:0') eval_epoch_loss=tensor(0.7565, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [08:26<00:00,  1.61it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=tensor(1.7221, device='cuda:0') train_epoch_loss=tensor(0.5435, device='cuda:0') eval_ppl=tensor(1.9109, device='cuda:0') eval_epoch_loss=tensor(0.6476, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # print(batch)\n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.detach().float()\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(valid_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eahc00/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8124fd53ceef45cf84ab9222d538c9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\n",
      "        \n",
      " title:[시정명령등처분취소청구의소]〈개인정보 유출로 인한 과징금 부과처분의 취소를 구한 사건〉 [공2023하,2029]\n",
      "판시사항:[1] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항 각호에서 정한 행위에 대하여 부과하는 과징금의 성격 / 위 조항 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이득 / 위 과징금 부과를 위한 관련 매출액을 산정할 때 ‘위반행위로 인하여 직접 또는 간접적으로 영향을 받는 서비스’의 범위를 판단하는 기준\n",
      "[2] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반에 대해 부과되는 과징금의 액수를 정할 때 고려할 사항 및 과징금의 액수가 위반행위의 내용에 비해 과중하여 사회통념상 현저하게 타당성을 잃은 경우, 과징금 부과처분이 위법한지 여부(적극)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# LoRA 적용 모델 불러오기\n",
    "base_model = AutoModelForCausalLM.from_pretrained(text_decoder_id)\n",
    "load_model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decoder_id)\n",
    "\n",
    "ds = get_dataset(split=\"valid\", get_prompy_only=True)\n",
    "\n",
    "\n",
    "i = 2\n",
    "inputs = tokenizer(ds[i]['prompt'], return_tensors=\"pt\")\n",
    "print(ds[i]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:144783 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n        user : 사건의 title과 판시사항을 보고 판결 결과와 그 이유를 예측해줘\\n        \\n title:[시정명령등처분취소청구의소]〈개인정보 유출로 인한 과징금 부과처분의 취소를 구한 사건〉 [공2023하,2029]\\n판시사항:[1] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항 각호에서 정한 행위에 대하여 부과하는 과징금의 성격 / 위 조항 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이득 / 위 과징금 부과를 위한 관련 매출액을 산정할 때 ‘위반행위로 인하여 직접 또는 간접적으로 영향을 받는 서비스’의 범위를 판단하는 기준\\n[2] 구 정보통신망 이용촉진 및 정보보호 등에 관한 법률 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반에 대해 부과되는 과징금의 액수를 정할 때 고려할 사항 및 과징금의 액수가 위반행위의 내용에 비해 과중하여 사회통념상 현저하게 타당성을 잃은 경우, 과징금 부과처분이 위법한지 여부(적극)\\n\\n    \\n원심판결 중 과징금 부과처분에 관한 부분을 파기하고 이 부분 사건을 다시 심리·판단하도록 원심법원에 환송하기로 하여, 관여 대법관의 일치된 의견으로 주문과 같이 판결한다.\\n상고이유를 판단한다.\\n1. 관련 법리\\n가. 구 「정보통신망 이용촉진 및 정보보호 등에 관한 법률」(2020. 5. 12. 법률 제16355호로 개정되기 전의 것, 이하 ‘2020법’이라 한다) 제64조의3 제1항은 “정보통신망 이용자가 정보통신망 사용자로부터 개인정보를 유출 또는 합승시킨다[개정 1], 개인 정보 보호를 위반하였다[개정 2]면 그 중 한 이하와 함께 과태모노폴로 벌금 500만원입니다.”로 다음과 같은 행위를 행위에 대하여 과징금을 부과하는 동시에 형사처벌이 이루어짐에 따라 그 과징금은 벌가요.(1) 2020법 제64조의3 제1항 제6호는 “자(전업·당업·대리자 등 제외)에 대하여 과징금을 부과함으로써 그 위반행위를 위반하는 이익의 범위를 과대하거나 초과함을 과대하는 행위라고 하더라도 과징금 부과를 통해 억착이나 강요와 같은 불법행위에 의한 처벌효과를 과대하는 점을 감안하지 않고 부과할 수 없다고 한 것에 반하여, 위 조항 제6호에서 지정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 이익이 인정되는 경우 그 제재효과가 미비하다고 하여 과징금이 박탈하고자 하는 이익의 가치를 고려하지 않고 부과할 수 없는 점을 추인한다고 한 규정 자체가 있었다.”라고 규정하고, 이 규정은 2020. 12. 상위법에 따라 개정된 2020법 제64조의5 제2호, 제3호가 개정되기 전의 내용에서 “자란 직접하거나 간접적으로 행위 또는 그 행위의 주체이고, 이익을 보호하거나 이행을 담당하거나 관리, 감독, 감독위원회의 직무를 하는 자연발생적 또는 법적으로 지정된 또는 지정된 개인을 말한다.”라고 규정하고, 2020법 제6호 제6호는 “자에 대하여 과징금을 부과함이 근로소비의 재연을 위한 법치에서 정당한 공익을 목적으로 하고, 근로소비의 대상이 되는 ‘서비스 이용 또는 개인 정보 유출, 개인 정보 침해 등’을 금지하는 것으로서 과징금이 자에 대하여 과징금이 부과됨으로써 근로자를 방해할 수 있는 이득이 제한되지만 여전히 방해되지 아니한 사이에 제한을 한다고 볼 수 있는 점을 의미한다.”이라고 규정하였다. 이 규정에 따라 과징금 부과처분이 형사처벌의 위조를 방지하기 위하여 허용되지 않는다[고론 1], 법규 위반 과징이 근로소비의 대상이 되는 행위에 대하여 부과함으로써 근로자의 거래를 방해하거나 방해할 우려가 있는 경우(원심판결 자료 조사로만 판결하는 것은 피고를 해치한다. 누구의 법규나 관행 등으로서도 부당한 악영향을 방지할 수 있는 과징금은 부과하되, 법규 위반에 대한 과징이 근로소비의 대상행위 또는 해당 행위에 대하여 다른 처벌 대상인 다른 처벌처분(형사처벌 또는 행정처벌)을 기대하는 것과 같이 하는 것은 허용된다.] (피고가 애초자들의 변호기로 청구한 기록에 따라 원심이 인정한 기록 있는 관점에서는 see 2008. 5. 22. 대법원 2007. 25. 대법번호 2008.3.22 전원준판 2008), 원심판결 이유를 참고한 결과, 피고의 이러한 상고이유에 대한 주장이 인정되는 부분은 위법하지만, 피고의 이러한 상고이유판단(이하 ‘이 사건 처분에 대한 상고이유판단’을 respectively calls)을 취소하고 제2, 3 상고이유 요청은 무시한 상태로 판단을 한다.\\n나. 2020법 제64조의3 제1항 제6호에서 정한 행위에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 영역을 위반하는 행위는 그 자에 대하여 과징금이 행위와 직계적으로 박탈하고자 하는 이익의 가치를 고려하여 부과하는 것과 비교하여, 과징금 부과를 통해 억착이나 강요와 같은 불법행위에 의한 처벌효과를 고려하는 것이 더 합리적이므로, 2020법 제64조의3 제1항에 따라 2020법 제6호에서 정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의성을 못 알아보는 것은 구 「개인정보보호법」(2020. 5. 20. 법률 제13765호로 개정되기 전의 것, 이하 ‘2020개인정보보호법’) 제6호의 자에 대하여 과징이 과태료로서의 형을 부과함으로써 행위자의 이익만을 중시하는 것과 같은 위 이유로, 피로로 인한 비난, 모욕, 욕설, 모욕적 행위 등 등 다른 형태의 인권침해 피해자가 발생할 우려가 있고 그 피해자는 과징금을 부담하여 개인정보 보호의 효과를 어느 정도 보장 받을 수 있을지도 않는 채 법치발달을 위한 과징금 부과처분에 그 법적 판매행위 변별, 서비스 이용을 방해하는 효과를 낼 수 있는 하찮은 500만원 또는 850만원 정도의 벌금에 그 책임을 이룬다고 볼 것은 추인되지 않아, 과징금 부과처분에 관련된 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)이 상당하게 적정하게 계산되어야 한다(대법원 2021. 9. 30. 선고 2021.17425 판결 등 참조).\\n나. 2020법 제64조의3 제1항에 따라 2020법 제6호 자에 대하여 과징금이 침해된 시점부터 90일 이내에 이를 바로 되돌려주어야 하는 것은 다른 법률의 긴급처벌청구 등과 같이 단순히 개인의 자유와 서비스 제공에 대한 제한이 전적으로 허용되는 것이 아니라, 법치발달을 위한 과징금 부과처분에 그 형의 성격에서 다른 처벌처분과 다른한다는 점, 「벌칙금 부과 절차」에서 다른 처벌금 부과과정의 원칙을 달리하여 추인하지 않고도 이 사건 사건 유형의 과징미를 부과할 수 있는 점 등 다른 여러 측면에서 고려하되, 위 규정에 따라 과징금이 부과된 행위와 연관하여 위반자인자의 이익을 중시하고, 부당한 침해의 정도가 크며 침해된 서비스 종류, 침해의 정도, 그로 인한 피해 정도, 부당한 침해를 방지하는 제재의 정도를 고려하여 적법하고 within 법정에 의한 수단이 되는 것만 제재 여부를 결정하되, 형사처벌의 위조를 방지하기 위하여 공무집행공무원은 과징금 부과처분에 관련 수익 계산 등으로 불필요한 부담을 피하고, 법치발전 과징금은 허가 또는 신고된 행위자의 이익을 최우선적으로 고려한다.\\n역대 기록 및 원심의 판단에 대한 예외를 제외하고, 피고가 이 사건 속지에서 개인 정보를 무단으로 유출하거나 개인 정보로 관련 서비스를 제공하면서 개인정보를 위반하였다는 사실이 인정한다. 원심은 이 사건 경험에 따라 “2020법 제2조 제2항 각호의 규정을 들어보면, 피고가 해당 정보를 어디에서나 찾아 판매했다면 해당 정보는 피고의 행위시에 이미 우리나라에 진출하거나 유입된 것으로 유추될 수 있고, 이 사건 경험으로 볼 때 대체로 피고의 행위 시에는 관련 서비스를 제공하는 업소에서 타인의 개인호를 쉽게 찾기만 하면서 개인정보를 무단으로 유출하는 경우가 되며, 피고의 행위시상은 미량인 다른 사람의 개인번호 또는 개인정보를 찾아하고 전달하는 일이라고 추정한다.”라는 이유로, 2020법 제64조의3 제1항에 따라 개인정보 보호조치 의무 위반으로 인한 personally identifiable information(PII)에 대하여 부과하는 과징금의 성격은 행위의 종류를 억제하는 처벌절차에 따른 처벌과 달리하고, 개인 업소에서 PII를 발견하거나 관리하고 전달하는 등의 행위는 그 업소에서 PII가 발생할하거나 관리하고 있는 것이므로 이 사건 사건 타입의 개인정보 유출 및 관련 서비스 제공 위반에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 범위를 중시함으로써을 요구하면 많이 초과되어 법치발달의 유효성과 공정함이 훼손될 수 있다. 이로써 2020법 제64조의3 제1에서 규정하는 과징금은 개별 서비스 이용자의 이익을 최우선적으로 고려하여 벌금의 형을 적용하고, 위 법 제6호에서 지정한 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의성을 못 알아보는 것은 구 「정보통신망 이용보안법」(2022. 12. 26. 법률 제17406호로 개정되기 전의 것, 이하 “정보통신망 이용보안법”이라 한다) 제6호의 자에 대하여 과징이 벌칙으로 처벌을 하는 것과 같이이므로, 2020법 제6호에서 지정한 자에 대하여 과징금을 자에 대하여 벌칙금 부과로 부과함으로써 위반행위를 중단하고 사업자의 정상적인 제공에 복귀하여 법통계의 개인정보 보호 수준이 적절하게 유지나 선진화하게 할 수 있는 이익의 가치를 추인하여야 한다. 이와 같은 법적 요구로 인해 2020법 제64조의3 제1에서 규정하는 과징금은 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)을 계산함으로써 벌금의 형을 계산하는 방식으로 취하는 것이다.\\n3. 상고이유 판단\\n가. 피고의 상고이유 주장과 관련된 부분은 아래에서 판단한다.\\n1) 2020법 제64조의3 제1항 각호에서 정한 행위에 대하여 부과되는 과징금의 성격과 위 규정에 따라 자에 대하여 과징금을 부과함으로써 박탈하고자 하는 이익의 영역을 중시하게 되는 법적 특성\\n피고1은 2023. 2. 8. 선고 where 2022. M.5.경 지위에서 인터넷을 통해 피고의 이 사건 속지에서 개인정보를 무단으로 유출하고, 피고의 이후에는 이 사건 개인정보를 판매했다(이하 “이 사건 개인 유출 및 관련 판매했을 때 침하’라고 한다)로 원고와 함께 “2020법 제2조 제2항 각고를 들어보면, 피고1이 2022. 2. 8.경 지소에서 피고2의 개인번호를 찾아 인지하고, 피고2가 2022. 3. 1.경 경인동 시지에 이 사건 개인번호를 검색한 때에는 2022. 3. 1.경 이 사건, 이 사건 뒤에 바로, 이 사건 자주 검색하는 것처럼 경험적으로 확인 없이 다른 곳에서 검색을 한 경우가 있고, 피고1에 의해 판매했다는 것처럼 명확하게 확인 가능한 경우는 아니었으므로, 이 사건 개인 검색의 행위는 업소에서 personal information를 발견하는 행위라고 볼 수 있고, 피고1에 의한 이 사건 개인 유출은 다른 사람의 개인정보를 무단으로 유출하는 행위라고 볼 수 있다. 나아가 원고는 2022. 2. 8. 5:30경 지소에서 “당연히 ○○○○○○○는 개인 정보가 이미 ○○○○○○○에서 출입한다고 인지하고 있고 ○○○○○○소에 아직 출입하지못하지만 다른 곳에서 출입하였다가 이 사건 개인정보를 피고에게 전하거나 판매했다고 말한다.”라고 말할 수 있고, 이 사건 경험으로 볼 때 피고1나 피고2가 내국인이라는 확인이 되었으므로, 개인 정보의 유출이나 취급 또는 판반이 한국인에게된 경우라고 볼 수 있으므로, 캐사래 또는 범죄의 발생이 많이 이루어지는 시점을 의미하지 않고 이 사건 사건 타입에서 다른 수단에 해당하는 것이다.\\n나. 피고1에 대한 과징금의 적용 여부에 관하여 원심은 참에 부합하는 행위의 횟수나 횟수는 총 일률로 수벌형벌의 원칙이 성립하지 않고, 범행의 종류를 억제하는 처벌효과를 위해 단순히 행위의 총 횟수를 고려할 수 있고, 서비스 이용을 금지나 제한할 수 없다고서, 이 사건 서비스 이용 침해 횟수는 7번이라고 했지만 이 사건 개인 다루기는 서비스 이용 이전이고, 피고1에 의한 불법 서비스 이용 횟수는 5번뿐이라는 등의 판단으로 이 사건 서비스 위반에 대하여 피고1의 자에 대하여 과징금을 부과함으로써 그로 인한 퇴진 및 퇴용 손해를 수반하게 한 것은 잘못이다( original opinion : 판단하기 어렵다).\\n다. 피고1가 2023. 2. 8.부터 2022. 11. 14.까지 수원을 하면서 10 times나 1/10의 비율로primogen prime red, prime blue, white, yellow, green, orange, purple, pink, violet, (prize) brown, (prize) black, (prize) white, (prize) red, (prize) blue, (prize) green, (prize) yellow, (prize) orange, (prize) purple, (prize) pink, (prize) violet, (prize) brown, (prize) black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, violet, brown, black, white, red, blue, green, yellow, orange, purple, pink, blond, (prize) brown, (prize) black, white, red, blue, green, yellow, orange, purple, pink, blond, (prize) white, red, blue, green, yellow, orange, purple, pink, blond, (prize) red, blue, green, yellow, orange, purple, pink, blond, (prize) blue, green, yellow, orange, purple, pink, blond, (prize) green, yellow, orange, purple, pink, blond, (prize) yellow, orange, purple, pink, blond, (prize) orange, purple, pink, blond, (prize) purple, pink, blond, (prize) pink, blond(이하 ‘이 사건 서비스 위반 각 유형’이라 한다)다고 하여, 피고의 자에 대하여 불법행위 취소나 금지요건이 이루어졌다.\\n서지에는 이 사건 서비스 위반 각 유형에 대한 검사내용으로 누락된 부분이 있다. 피고1에 대한 과징금 부과처에 관한 상고이유 주장의 논리와 검사절차의 사실을 위 법리를 적용하여 판단한다.\\n1. 피고1에 대한 자에 대하여 과징금을 부과함으로써 퇴진이나 퇴용 손해를 수반하게 한 것은 불법행위 취소요건에 수긍한다.\\n2. 이 사건 서비스 위반 각 유형에 관한 피고1의 불법행위 취소 요건에 관하여\\n가. 이 사건 서비스 위반 각 종류에 대한 검사내용에 의하면 이 사건 서비스 이전에 피고1은 피고2의 개인번호를 찾아 인지하였고, 피고1이 이 사건 서비스행위를 하고 나서 피고2의 개인번호를 찾아 고지하였다는 사실을 알 수 있으므로, 실질적으로 이 사건 서비스행위를 통해 피고2의 개인정보를 수신했다는 것을 볼 수 있다. 따라서 피고1은 2020법 제64조의3 제1항 각호에서 정한 행위에 관하여 개인정보를 유출하거나 제공하였다. 이에 따라 피고1에게 이 사건 10 at. 25. 10. 21. 10:00경 경인동 시지에 이 사건 개인 발견 및 처리의 의무 위반에 관한 과징금이 부과되었다.\\n나. 피고1이 이 사건 서비스행위를 하면서 피고2가 already in these countries인 경우에는 캐사래 또는 범죄의 발생이 많이 일어날 수 있으므로, 이 사건 서비스 위반은 다른 수단에 해당하는 것이다.\\n다. 피고1의 자에 대하여 과징금을 집행하는 과정에서 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)을 계산하는 과정은 피고1에 대한벌칙금 집행 당시 이와 동일하므로, 피고1에 대한 이 사건 서비스 위반에 대한 과징금 부과처리에서도 관련 수익 계산이 이루어져야 한다. 이에 따라 위 법리에 따라 피고1에 대한 이 사건 서비스 위반의 과징금 집행 관련 수익(벌칙금 부과 후 30일 내에 납부할 수 있는 일정액)은 ‘1·100·1·50·1·30’ 단위이므로, 이 사건 서비스 위반의 과징금은 1원이다.\\n서지 관련 법리나 그 기록에 대하여 별도로 검사하지 아니하므로 이 사건 공소이유를 기각한다.']\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"])\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
